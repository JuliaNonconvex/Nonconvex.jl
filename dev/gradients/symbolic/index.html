<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Symbolic differentiation · Nonconvex.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Nonconvex.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Getting started</a></li><li><span class="tocitem">Problem definition</span><ul><li><a class="tocitem" href="../../problem/problem/">Overview</a></li><li><a class="tocitem" href="../../problem/model/"><code>Model</code> definition</a></li><li><a class="tocitem" href="../../problem/dict_model/"><code>DictModel</code> definition</a></li><li><a class="tocitem" href="../../problem/queries/">Querying models</a></li></ul></li><li><span class="tocitem">Gradients, Jacobians and Hessians</span><ul><li><a class="tocitem" href="../gradients/">Overview</a></li><li><a class="tocitem" href="../user_defined/">User-defined gradient, Jacobian or Hessian</a></li><li><a class="tocitem" href="../other_ad/">Using other AD packages</a></li><li><a class="tocitem" href="../chainrules_fd/">Using ChainRules in ForwardDiff</a></li><li><a class="tocitem" href="../sparse/">Sparse Jacobian or Hessian</a></li><li class="is-active"><a class="tocitem" href>Symbolic differentiation</a><ul class="internal"><li><a class="tocitem" href="#Background"><span>Background</span></a></li><li><a class="tocitem" href="#Symbolifying-a-function"><span>Symbolifying a function</span></a></li><li><a class="tocitem" href="#Symbolifying-a-model"><span>Symbolifying a model</span></a></li></ul></li><li><a class="tocitem" href="../implicit/">Implicit differentiation</a></li><li><a class="tocitem" href="../history/">Storing history of gradients</a></li></ul></li><li><span class="tocitem">Algorithms</span><ul><li><a class="tocitem" href="../../algorithms/algorithms/">Overview</a></li><li><a class="tocitem" href="../../algorithms/mma/">Method of moving asymptotes in pure Julia</a></li><li><a class="tocitem" href="../../algorithms/ipopt/">Interior point method using <code>Ipopt.jl</code></a></li><li><a class="tocitem" href="../../algorithms/nlopt/">Various optimization algorithms from <code>NLopt.jl</code></a></li><li><a class="tocitem" href="../../algorithms/auglag/">Augmented Lagrangian algorithm in pure Julia</a></li><li><a class="tocitem" href="../../algorithms/minlp/">First and second order mixed integer nonlinear programming algorithms</a></li><li><a class="tocitem" href="../../algorithms/hyperopt/">Multi-start and hyper-parameter optimization in pure Julia</a></li><li><a class="tocitem" href="../../algorithms/surrogate/">Surrogate-assisted continuous and discrete, constrained optimization</a></li><li><a class="tocitem" href="../../algorithms/mts/">Multi-trajectory search algorithm in pure Julia</a></li><li><a class="tocitem" href="../../algorithms/sdp/">Interior point meta-algorithm for handling nonlinear semidefinite constraints</a></li><li><a class="tocitem" href="../../algorithms/metaheuristics/">A collection of meta-heuristic algorithms in pure Julia</a></li><li><a class="tocitem" href="../../algorithms/nomad/">Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization</a></li><li><a class="tocitem" href="../../algorithms/tobs/">Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic</a></li></ul></li><li><a class="tocitem" href="../../result/">Optimization result</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Gradients, Jacobians and Hessians</a></li><li class="is-active"><a href>Symbolic differentiation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Symbolic differentiation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaNonconvex/Nonconvex.jl/blob/master/docs/src/gradients/symbolic.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Symbolic-differentiation"><a class="docs-heading-anchor" href="#Symbolic-differentiation">Symbolic differentiation</a><a id="Symbolic-differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Symbolic-differentiation" title="Permalink"></a></h1><h2 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h2><p>For functions, a tractable symbolic gradient/Jacobian/Hessian may exist. <a href="https://github.com/JuliaSymbolics/Symbolics.jl"><code>Symbolics.jl</code></a> is a symbolic mathematics package in Julia that can uncover the mathematical expression from Julia functions and then symbolically differentiate the resulting expression. Symbolic simplifications and cancellations can sometimes lead to computational savings compared to algorithmic differentiation. Symbolic differentiation can further exploit the sparsity of the graident, Jacobian and/Hessian if one exists.</p><p>In <code>Nonconvex</code>, you can enforce the use of <code>Symbolics</code> to symbolically differentiate specific functions using the <code>symbolify</code> function modifier. In particular, the <code>Symbolics</code>-derived gradient/Jacobian/Hessian functions will be used whenever <code>ForwardDiff</code> or any <code>ChainRules</code>-compatible AD package such as <code>Zygote</code> is used to differentiate the modified function.</p><h2 id="Symbolifying-a-function"><a class="docs-heading-anchor" href="#Symbolifying-a-function">Symbolifying a function</a><a id="Symbolifying-a-function-1"></a><a class="docs-heading-anchor-permalink" href="#Symbolifying-a-function" title="Permalink"></a></h2><h3 id="First-order-derivatives"><a class="docs-heading-anchor" href="#First-order-derivatives">First order derivatives</a><a id="First-order-derivatives-1"></a><a class="docs-heading-anchor-permalink" href="#First-order-derivatives" title="Permalink"></a></h3><p>In order to force <code>Nonconvex</code> to use <code>Symbolics</code> when differentiating a function <code>f(x...)</code> once, the <code>symbolify</code> function modifier can be used:</p><pre><code class="language-julia hljs">F = symbolify(f, x...; hessian = false, sparse = false, simplify = false)
F(x...)</code></pre><p>where <code>x</code> is some sample input arguments to <code>f</code>. <code>F(x...)</code> can now be used inplace of <code>f(x...)</code> in objectives and/or constraints to be differentiated. Whenever <code>ForwardDiff</code> or any <code>ChainRules</code>-compatible AD package such as <code>Zygote</code> is used to differentiate <code>F</code> once, the <code>Symbolics</code>-derived gradient/Jacobian will now be used.</p><p>The <code>sparse</code> keyword argument can be set to <code>true</code> (default is <code>false</code>) to tell <code>Symbolics</code> to return a sparse gradient/Jacobian for the function <code>F</code>. The <code>simplify</code> keyword argument can be set to <code>true</code> (default is <code>false</code>) to tell <code>Symbolics</code> to simplify the mathematical expressions for the gradient/Jacobian functions.</p><h3 id="Second-order-derivatives"><a class="docs-heading-anchor" href="#Second-order-derivatives">Second order derivatives</a><a id="Second-order-derivatives-1"></a><a class="docs-heading-anchor-permalink" href="#Second-order-derivatives" title="Permalink"></a></h3><p>When <code>hessian = false</code> (the default value), only the Jacobian/gradient of <code>F</code> will be computed with <code>Symbolics</code>. In order to use <code>Symbolics</code> to differentiate the function <code>F</code> twice, you can set <code>hessian = true</code>. Setting <code>hessian = true</code> will also work for vector-valued functions <code>f</code> or for functions <code>f</code> that return multiple, non-vector outputs. The <code>sparse</code> and <code>simplify</code> keyword arguments work the same way when <code>hessian</code> is set to <code>true</code>.</p><h2 id="Symbolifying-a-model"><a class="docs-heading-anchor" href="#Symbolifying-a-model">Symbolifying a model</a><a id="Symbolifying-a-model-1"></a><a class="docs-heading-anchor-permalink" href="#Symbolifying-a-model" title="Permalink"></a></h2><p>Instead of symbolifying one function at a time, the user can instead symbolify an entire <code>Nonconvex</code> model including the objective, all the inequality constraint functions, all the equality constraint functions and all the semidefinite constraint functions.</p><pre><code class="language-julia hljs">sym_model = symbolify(model, hessian = true, simplify = true, sparse = true)</code></pre><p>where <code>model</code> is of type <code>Model</code> or <code>DictModel</code> and <code>hessian</code>, <code>simplify</code> and <code>sparse</code> have the same intepretation from the function symbolification above. <code>sym_model</code> can now be optimized using any of the <code>Nonconvex</code> algorithms compatible with the model.</p><p>By default, the objective and all the constraint functions will be symbolified. To prevent the symbolification of some component of the model, any of the following keyword arguments can be set to <code>false</code> (default is <code>true</code>):</p><ul><li><code>objective = false</code></li><li><code>ineq_constraints = false</code></li><li><code>eq_constraints = false</code></li><li><code>sd_constraints = false</code></li></ul><p>Setting the <code>objective</code>, <code>ineq_constraints</code>, <code>eq_constraints</code>, and/or <code>sd_constraints</code> keyword arguments to <code>false</code> (default is <code>true</code>) will prevent the symbolification of the objective, all the inequality constraint functions, all the equality constraint functions, and/or all the semidefinite constraint functions respectively.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../sparse/">« Sparse Jacobian or Hessian</a><a class="docs-footer-nextpage" href="../implicit/">Implicit differentiation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.21 on <span class="colophon-date" title="Friday 15 July 2022 11:02">Friday 15 July 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
