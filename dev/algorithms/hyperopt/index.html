<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Multi-start and hyper-parameter optimization in pure Julia · Nonconvex.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Nonconvex.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Getting started</a></li><li><span class="tocitem">Problem definition</span><ul><li><a class="tocitem" href="../../problem/problem/">Overview</a></li><li><a class="tocitem" href="../../problem/model/"><code>Model</code> definition</a></li><li><a class="tocitem" href="../../problem/dict_model/"><code>DictModel</code> definition</a></li><li><a class="tocitem" href="../../problem/queries/">Querying models</a></li></ul></li><li><span class="tocitem">Gradients, Jacobians and Hessians</span><ul><li><a class="tocitem" href="../../gradients/gradients/">Overview</a></li><li><a class="tocitem" href="../../gradients/user_defined/">User-defined gradient, Jacobian or Hessian</a></li><li><a class="tocitem" href="../../gradients/other_ad/">Using other AD packages</a></li><li><a class="tocitem" href="../../gradients/chainrules_fd/">Using ChainRules in ForwardDiff</a></li><li><a class="tocitem" href="../../gradients/sparse/">Sparse Jacobian or Hessian</a></li><li><a class="tocitem" href="../../gradients/symbolic/">Symbolic differentiation</a></li><li><a class="tocitem" href="../../gradients/implicit/">Implicit differentiation</a></li><li><a class="tocitem" href="../../gradients/history/">Storing history of gradients</a></li></ul></li><li><span class="tocitem">Algorithms</span><ul><li><a class="tocitem" href="../algorithms/">Overview</a></li><li><a class="tocitem" href="../mma/">Method of moving asymptotes in pure Julia</a></li><li><a class="tocitem" href="../ipopt/">Interior point method using <code>Ipopt.jl</code></a></li><li><a class="tocitem" href="../nlopt/">Various optimization algorithms from <code>NLopt.jl</code></a></li><li><a class="tocitem" href="../auglag/">Augmented Lagrangian algorithm in pure Julia</a></li><li><a class="tocitem" href="../minlp/">First and second order mixed integer nonlinear programming algorithms</a></li><li class="is-active"><a class="tocitem" href>Multi-start and hyper-parameter optimization in pure Julia</a><ul class="internal"><li><a class="tocitem" href="#Description"><span>Description</span></a></li><li><a class="tocitem" href="#Quick-start"><span>Quick start</span></a></li><li><a class="tocitem" href="#Construct-an-instance"><span>Construct an instance</span></a></li><li><a class="tocitem" href="#Options"><span>Options</span></a></li></ul></li><li><a class="tocitem" href="../surrogate/">Surrogate-assisted continuous and discrete, constrained optimization</a></li><li><a class="tocitem" href="../mts/">Multi-trajectory search algorithm in pure Julia</a></li><li><a class="tocitem" href="../sdp/">Interior point meta-algorithm for handling nonlinear semidefinite constraints</a></li><li><a class="tocitem" href="../metaheuristics/">A collection of meta-heuristic algorithms in pure Julia</a></li><li><a class="tocitem" href="../nomad/">Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization</a></li><li><a class="tocitem" href="../tobs/">Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic</a></li></ul></li><li><a class="tocitem" href="../../result/">Optimization result</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Algorithms</a></li><li class="is-active"><a href>Multi-start and hyper-parameter optimization in pure Julia</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Multi-start and hyper-parameter optimization in pure Julia</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaNonconvex/Nonconvex.jl/blob/master/docs/src/algorithms/hyperopt.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Multi-start-and-hyper-parameter-optimization-in-pure-Julia"><a class="docs-heading-anchor" href="#Multi-start-and-hyper-parameter-optimization-in-pure-Julia">Multi-start and hyper-parameter optimization in pure Julia</a><a id="Multi-start-and-hyper-parameter-optimization-in-pure-Julia-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-start-and-hyper-parameter-optimization-in-pure-Julia" title="Permalink"></a></h1><h2 id="Description"><a class="docs-heading-anchor" href="#Description">Description</a><a id="Description-1"></a><a class="docs-heading-anchor-permalink" href="#Description" title="Permalink"></a></h2><p><a href="https://github.com/baggepinnen/Hyperopt.jl">Hyperopt.jl</a> is a Julia library that implements a number of hyperparameter optimization algorithms which can be used to optimize the starting point of the optimization. <code>NonconvexHyperopt.jl</code> allows the use of the algorithms in <code>Hyperopt.jl</code> as meta-algorithms using the <code>HyperoptAlg</code> struct.</p><h2 id="Quick-start"><a class="docs-heading-anchor" href="#Quick-start">Quick start</a><a id="Quick-start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-start" title="Permalink"></a></h2><p>Given a model <code>model</code> and an initial solution <code>x0</code>, the following can be used to optimize the model using Hyperopt.</p><pre><code class="language-julia hljs">using Nonconvex
Nonconvex.@load Hyperopt

alg = HyperoptAlg(IpoptAlg())
options = HyperoptOptions(sub_options = IpoptOptions(), sampler = GPSampler())
result = optimize(model, alg, x0, options = options)</code></pre><p>Hyperopt is an optional dependency of Nonconvex so you need to import it in order to use it. <code>HyperoptAlg</code> can wrap any other algorithm in Nonconvex, e.g. <code>IpoptAlg()</code>. When the algorithm is a <code>HyperoptAlg</code>, the <code>options</code> keyword argument must of type <code>HyperoptOptions</code>. For more on the options available see below.</p><h2 id="Construct-an-instance"><a class="docs-heading-anchor" href="#Construct-an-instance">Construct an instance</a><a id="Construct-an-instance-1"></a><a class="docs-heading-anchor-permalink" href="#Construct-an-instance" title="Permalink"></a></h2><p>To construct an instance of the Hyperopt + Ipopt algorithm, use:</p><pre><code class="language-julia hljs">alg = HyperoptAlg(IpoptAlg())</code></pre><p><code>HyperoptAlg</code> can wrap any other algorithm in Nonconvex, e.g. <code>NLoptAlg(:LD_MMA)</code> or <code>AugLag()</code>.</p><h2 id="Options"><a class="docs-heading-anchor" href="#Options">Options</a><a id="Options-1"></a><a class="docs-heading-anchor-permalink" href="#Options" title="Permalink"></a></h2><p>The options keyword argument to the <code>optimize</code> function shown above must be an instance of the <code>HyperoptOptions</code> struct when the algorihm is a <code>HyperoptAlg</code>. To specify options, use keyword arguments in the constructor of <code>HyperoptOptions</code>. The <code>sampler</code> keyword argument determines the sampling algorithm used to propose new starting points in the multi-start procedure. The <code>sub_options</code> keyword argument can be used to pass in the options for the sub-optimizer. There are 2 different ways to pass the sub-options depending on the sampler type.</p><p>The <code>sampler</code> argument can be of type:</p><ol><li><code>RandomSampler</code></li><li><code>LHSampler</code></li><li><code>CLHSampler</code></li><li><code>GPSampler</code></li><li><code>Hyperband</code></li></ol><p>When optimizing the starting point, the upper and lower bounds on the initial solution must be finite, or finite bounds must be passed in to the <code>options</code> constructor. All the options that can be passed to the <code>HyperoptOptions</code> constructor are listed below:</p><article class="docstring"><header><a class="docstring-binding" id="NonconvexMultistart.HyperoptOptions" href="#NonconvexMultistart.HyperoptOptions"><code>NonconvexMultistart.HyperoptOptions</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HyperoptOptions: options performing starting point optimization using Hyperopt.jl</code></pre><ul><li><code>sub_options</code>: options for the sub-optimizer.</li><li><code>lb</code>: Lower bound of starting point, if don&#39;t specify it, the default value will be <code>nothing</code>,            then will end up be replaced by the lower bound of optimization problem.</li><li><code>ub</code>: Upper bound of starting point, same as above. </li><li><code>searchspace_size::Integer</code>: How many potential starting points we generate.</li><li><code>iters::Integer</code>: Among all generated potential starting points, how many of them will be evaluated. </li><li><code>sampler::Hyperopt.Sampler</code>: An instance of &#39;Hyperopt.Sampler&#39;, which decides search algorithm. </li><li><code>ctol</code>: infeasibility tolerance for accepting a solution as feasible</li><li><code>keep_all</code>: if true, all the solutions of the sub-problems will be saved</li></ul></div></section></article><h3 id="Sampler-choice"><a class="docs-heading-anchor" href="#Sampler-choice">Sampler choice</a><a id="Sampler-choice-1"></a><a class="docs-heading-anchor-permalink" href="#Sampler-choice" title="Permalink"></a></h3><h4 id="RandomSampler,-LHSampler,-CLHSampler-and-GPSampler"><a class="docs-heading-anchor" href="#RandomSampler,-LHSampler,-CLHSampler-and-GPSampler">RandomSampler, LHSampler, CLHSampler and GPSampler</a><a id="RandomSampler,-LHSampler,-CLHSampler-and-GPSampler-1"></a><a class="docs-heading-anchor-permalink" href="#RandomSampler,-LHSampler,-CLHSampler-and-GPSampler" title="Permalink"></a></h4><p>All the sampler constructors are functions defined in Nonconvex wrapping the Hyperopt alternatives to define defaults. For <code>GPSampler</code>, <code>Hyperopt.Min</code> is always used by default in Nonconvex so you should not pass this argument. All the other arguments that can be passed to the sampler constructor can be found in the <a href="https://github.com/baggepinnen/Hyperopt.jl#details">Hyperopt documentation</a>. Example:</p><pre><code class="language-julia hljs">options = HyperoptOptions(sub_options = IpoptOptions(), sampler = GPSampler())</code></pre><h4 id="Hyperband"><a class="docs-heading-anchor" href="#Hyperband">Hyperband</a><a id="Hyperband-1"></a><a class="docs-heading-anchor-permalink" href="#Hyperband" title="Permalink"></a></h4><p>The <a href="https://github.com/baggepinnen/Hyperopt.jl#hyperband">Hyperband algorithm</a> in Hyperopt requires a different way to pass in the sub-options. The Hyperband algorithm tries to optimize the allocation of resources. The <code>sub_options</code> argument must be a function with input as the &quot;resources&quot; and output as the sub-solver options. The <code>Hyperband</code> constructor accepts 3 arguments:</p><ol><li>The maximum resources <code>R</code></li><li><code>η</code> which roughly determines the proportion of trials discarded between each round of successive halving</li><li><code>inner</code> which specifies an inner sampler of type <code>RandomSampler</code>, <code>LHSampler</code> or <code>CLHSampler</code>.</li></ol><p>Example:</p><pre><code class="language-julia hljs">options = HyperoptOptions(
    sub_options = max_iter -&gt; IpoptOptions(max_iter = max_iter), 
    sampler = Hyperband(R=100, η=3, inner=RandomSampler()),
)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../minlp/">« First and second order mixed integer nonlinear programming algorithms</a><a class="docs-footer-nextpage" href="../surrogate/">Surrogate-assisted continuous and discrete, constrained optimization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Thursday 13 July 2023 20:55">Thursday 13 July 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
