var documenterSearchIndex = {"docs":
[{"location":"algorithms/metaheuristics/#A-collection-of-meta-heuristic-algorithms-in-pure-Julia","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"","category":"section"},{"location":"algorithms/metaheuristics/#Description","page":"A collection of meta-heuristic algorithms in pure Julia","title":"Description","text":"","category":"section"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"Metaheuristics.jl is an optimization library with a collection of metaheuristic optimization algorithms implemented. NonconvexMetaheuristics.jl allows the use of all the algorithms in the Metaheuristics.jl using the MetaheuristicsAlg struct.","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"The main advantage of metaheuristic algorithms is that they don't require the objective and constraint functions to be differentiable. One advantage of the Metaheuristics.jl package compared to other black-box optimization or metaheuristic algorithm packages is that a large number of the algorithms implemented in Metaheuristics.jl support bounds, inequality and equality constraints using constraint handling techniques for metaheuristic algorithms.","category":"page"},{"location":"algorithms/metaheuristics/#Supported-algorithms","page":"A collection of meta-heuristic algorithms in pure Julia","title":"Supported algorithms","text":"","category":"section"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"Nonconvex.jl only supports the single objective optimization algorithms in Metaheuristics.jl. The following algorithms are supported:","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"Evolutionary Centers Algorithm (ECA)\nDifferential Evolution (DE)\nDifferential Evolution (PSO)\nArtificial Bee Colony (ABC)\nGravitational Search Algorithm (CGSA)\nSimulated Annealing (SA)\nWhale Optimization Algorithm (WOA)\nMachine-coded Compact Genetic Algorithm (MCCGA)\nGenetic Algorithm (GA)","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"For a summary of the strengths and weaknesses of each algorithm above, please refer to the table in the algorithms page in the Metaheuristics documentation. To define a Metaheuristics algorithm, you can use the MetaheuristicsAlg algorithm struct which wraps one of the above algorithm types, e.g. MetaheuristicsAlg(ECA) or MetaheuristicsAlg(DE).","category":"page"},{"location":"algorithms/metaheuristics/#Quick-start","page":"A collection of meta-heuristic algorithms in pure Julia","title":"Quick start","text":"","category":"section"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Metaheuristics.","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"using Nonconvex\nNonconvex.@load Metaheuristics\n\nalg = MetaheuristicsAlg(ECA)\noptions = MetaheuristicsOptions(N = 1000) # population size\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"Metaheuristics is an optional dependency of Nonconvex so you need to load the package to be able to use it.","category":"page"},{"location":"algorithms/metaheuristics/#Options","page":"A collection of meta-heuristic algorithms in pure Julia","title":"Options","text":"","category":"section"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"The options keyword argument to the optimize function shown above must be an instance of the MetaheuristicsOptions struct when the algorihm is a MetaheuristicsAlg. To specify options use keyword arguments in the constructor of MetaheuristicsOptions, e.g:","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"options = MetaheuristicsOptions(N = 1000)","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"All the other options that can be set for each algorithm can be found in the algorithms section of the documentation of Metaheuristics.jl. Note that one notable difference between using Metaheuristics directly and using it through Nonconvex is that in Nonconvex, all the options must be passed in through the options struct and only the algorithm type is part of the alg struct.","category":"page"},{"location":"algorithms/metaheuristics/#Variable-bounds","page":"A collection of meta-heuristic algorithms in pure Julia","title":"Variable bounds","text":"","category":"section"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"When using Metaheuristics algorithms, finite variables bounds are necessary. This is because the initial population is sampled randomly in the finite interval of each variable. Use of Inf as an upper bound or -Inf is therefore not acceptable.","category":"page"},{"location":"algorithms/metaheuristics/#Initialization","page":"A collection of meta-heuristic algorithms in pure Julia","title":"Initialization","text":"","category":"section"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"Most metaheuristic algorithms are population algorithms which can accept multiple initial solutions to be part of the initial population. In Nonconvex, you can specify multiple initial solutions by making x0 a vector of solutions. However, since Nonconvex models support arbitrary collections as decision variables, you must specify that the x0 passed in is indeed a population of solutions rather than a single solution that's a vector of vectors for instance. To specify that x0 is a vector of solutions, you can set the multiple_initial_solutions option to true in the options struct, e.g:","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"options = MetaheuristicsOptions(N = 1000, multiple_initial_solutions = true)\nx0 = [[1.0, 1.0], [0.0, 0.0]]","category":"page"},{"location":"algorithms/metaheuristics/","page":"A collection of meta-heuristic algorithms in pure Julia","title":"A collection of meta-heuristic algorithms in pure Julia","text":"When fewer solutions are passed in x0 compared to the population size, random initial solutions between the lower and upper bounds are sampled to complete the initial population.","category":"page"},{"location":"problem/problem/#Problem-definition","page":"Overview","title":"Problem definition","text":"","category":"section"},{"location":"problem/problem/","page":"Overview","title":"Overview","text":"There are 3 ways to define a model in Nonconvex.jl:","category":"page"},{"location":"problem/problem/","page":"Overview","title":"Overview","text":"Model which assumes all the variables are indexed by an integer index starting from 1. The decision variables are therefore a vector.\nDictModel which assumes each variable has a name. The decision variables are stored in an OrderedDict, an ordered dictionary data structure.\nStart from JuMP.Model and convert it to DictModel. This is convenient to make use of JuMP's user-friendly macros for variable and linear expression, objective or constraint definitions.","category":"page"},{"location":"problem/problem/#Table-of-contents","page":"Overview","title":"Table of contents","text":"","category":"section"},{"location":"problem/problem/","page":"Overview","title":"Overview","text":"Pages = [\"model.md\", \"dict_model.md\", \"queries.md\"]\nDepth = 3","category":"page"},{"location":"result/#Optimization-result","page":"Optimization result","title":"Optimization result","text":"","category":"section"},{"location":"result/","page":"Optimization result","title":"Optimization result","text":"Each algorithm is free to return a different result type from the optimize function. However, all the result types have 2 fields:","category":"page"},{"location":"result/","page":"Optimization result","title":"Optimization result","text":"result.minimum: stores the minimum objective value reached in the optimization\nresult.minimizer: stores the optimal decision variables reached during optimization","category":"page"},{"location":"result/","page":"Optimization result","title":"Optimization result","text":"Some result types store additional information returned by the solver, e.g. the convergence status. Please explore the fields of the result output from optimize and/or check the documentation of the individual algorithms in the algorithms section of the documentation. If you have further questions, feel free to open issues in the Nonconvex.jl repository.","category":"page"},{"location":"algorithms/sdp/#Interior-point-meta-algorithm-for-handling-nonlinear-semidefinite-constraints","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","text":"","category":"section"},{"location":"algorithms/sdp/#Description","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Description","text":"","category":"section"},{"location":"algorithms/sdp/","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","text":"If you need to keep your any matrix-valued function of the decision variables positive semidefinite, Nonconvex supports an interface for the barrier method for semidefinite programming, which is a meta-algorithm transforming the optimization problem to a series of nonlinear programming problems and solving them using the pre-specified sub_alg and sub_options.","category":"page"},{"location":"algorithms/sdp/#Quick-start","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Quick start","text":"","category":"section"},{"location":"algorithms/sdp/","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","text":"Optimizing over a multivariate gaussian distribution with artificial samples using Ipopt:","category":"page"},{"location":"algorithms/sdp/","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","text":"using Nonconvex, Distributions\nNonconvex.@load Semidefinite Ipopt\n\n# Draw random multivariate gaussian samples\n# Random groundtruth\nmat_dim = 3\nμ = randn(mat_dim)\nΣ = rand(mat_dim, mat_dim)\nΣ = Σ + Σ' + 2I\n# Generate\nn_sample = 1000\nsamples = rand(MvNormal(μ, Σ), n_sample)\n\n# Define objective function\nfunction f((x_L, x_D))\n    return -loglikelihood(MvNormal(μ, decompress_symmetric(x_L, x_D)), samples)\nend\n# Define the matrix-valued function\nfunction sd_constraint((x_L, x_D))\n    return decompress_symmetric(x_L, x_D)\nend\n\n# Define settings\nmodel = Model(f)\nmat_x0 = rand(mat_dim, mat_dim)\nmat_x0 = mat_x0 + mat_x0' + I\n\nx0 = [mat_x0[NonconvexSemidefinite.lowertriangind(mat_x0)], diag(mat_x0)]\nlbs = [fill(-Inf, length(x0[1])), zeros(length(x0[2]))]\nubs = [fill(Inf, length(x0[1])), fill(Inf, length(x0[2]))]\naddvar!(model, lbs, ubs)\nadd_sd_constraint!(model, sd_constraint)\nalg = SDPBarrierAlg(sub_alg=IpoptAlg())\noptions = SDPBarrierOptions(sub_options=IpoptOptions(max_iter=200), n_iter = 20)\n\n# Optimize\nresult = optimize(model, alg, x0, options = options)\n\n# Relative error norm\nnorm(sd_constraint(result.minimizer) - Σ) / norm(Σ)","category":"page"},{"location":"algorithms/sdp/#Options","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Options","text":"","category":"section"},{"location":"algorithms/sdp/","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","text":"SDPBarrierOptions","category":"page"},{"location":"algorithms/sdp/#NonconvexSemidefinite.SDPBarrierOptions","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"NonconvexSemidefinite.SDPBarrierOptions","text":"SDPBarrierOptions(; kwargs...)\n\nThe keyword arguments which can be specified are:\n\nc_init: (default 1.0) initial value for the coefficient c that is multiplied by the barrier term, could be a real number or vector in the case of multiple semidefinite constraints.\nc_decr: (default 0.1) decreasing rate (< 1) that multiplies the barrier term in every iteration, could be either a real number or a vector in the case of multiple semidefinite constraints.\nn_iter: (default 20) number of sub-problems to solve in the barrier method.\nsub_options: options for the sub-problem's solver\nkeep_all: (default falue) if set to true, SDPBarrierResult stores the results from all the iterations\n\n\n\n\n\n","category":"type"},{"location":"algorithms/sdp/#Optimizer","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Optimizer","text":"","category":"section"},{"location":"algorithms/sdp/","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","text":"SDPBarrierAlg","category":"page"},{"location":"algorithms/sdp/#NonconvexSemidefinite.SDPBarrierAlg","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"NonconvexSemidefinite.SDPBarrierAlg","text":"SDPBarrierAlg(sub_alg)\n\nA meta-algorithm that handles semidefinite constraints on nonlinear functions using a barrier approach. The coefficient of the barrier term is exponentially decayed and the sub-problems are solved using sub_alg. sub_alg can be any other compatible solver from Nonconvex.jl. The solver must be able to solve the sub-problem after removing the semidefinite constraints. The options to the solver should be pased to the SDPBarrierOptions struct and passed in as the options to the optimize function. Call ? SDPBarrierOptions to check all the different options that can be set.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/sdp/#Matrix-interfaces","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Matrix interfaces","text":"","category":"section"},{"location":"algorithms/sdp/","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","text":"For every n*n real positive semidefinite matrix that optimization objective contains, please have two inputs x_L and x_D representing the lower-triangular and the diagonal part of it. In the function, call decompress_symmetric(x_L, x_d) to represent that matrix, which will be handled by Nonocnvex automatically","category":"page"},{"location":"algorithms/sdp/","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","text":"decompress_symmetric","category":"page"},{"location":"algorithms/sdp/#NonconvexSemidefinite.decompress_symmetric","page":"Interior point meta-algorithm for handling nonlinear semidefinite constraints","title":"NonconvexSemidefinite.decompress_symmetric","text":"decompress_symmetric\n\nFor example:      a 3*3 positive semidefinite matrix:      [  a       b       d;          b       c       e;          d       e       f       ]      represents by:      [  x_D[1]  x_L[3]  x_L[2];          x_L[1]  x_D[2]  x_L[1];          x_L[2]  x_L[3]  x_D[3]  ]\n\nx_L::AbstractArray: representing lower triangular part of a n*n matrix, length should be (n^2-n)÷2\nx_D::AbstractArray: representing diagonal part of a n*n matrix, length should be n\n\n\n\n\n\n","category":"function"},{"location":"problem/model/#Model-definition","page":"Model definition","title":"Model definition","text":"","category":"section"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To define an empty model, run:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"model =  Model()","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To specify an objective function obj when creating the model, run:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"model = Model(obj)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"where obj is a function that takes a single vector argument.","category":"page"},{"location":"problem/model/#Variable-definition","page":"Model definition","title":"Variable definition","text":"","category":"section"},{"location":"problem/model/#Add-a-single-variable","page":"Model definition","title":"Add a single variable","text":"","category":"section"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To add a new variable to a Model with lower and upper bounds lb and ub respectively, use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"addvar!(model, lb, ub)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"The variables added will be stacked on top of each other with a linear integer index. The lower and upper bounds for each variable don't have to be numbers, they can be:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"Dictionaries\nStructs\nTuples\nNamedTuples\nNested data structures","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"However, the values input cannot be vectors. A vector input has a different interpretation. See the next section.","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"The types of the lower and upper bounds of each variable must be the same and this type will be assumed to be the type of the decision variable. Different variables can have different types though. Vectorization and de-vectorization are handled automatically by Nonconvex.","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To specify an initial value, use the init keyword argument. To add an integer constraint on the variable, use the integer keyword argument. For example:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"addvar!(model, 0.0, 10.0, init = 1.0, integer = true)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"init must have the same type as the lower and upper bounds.","category":"page"},{"location":"problem/model/#Add-multiple-variables","page":"Model definition","title":"Add multiple variables","text":"","category":"section"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To add multiple variables simultaneously, pass in a vector of values for the bounds and optionally for the init and integer keyword arguments.","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"addvar!(model, [0.0, 0.0], [10.0, 10.0], init = [1.0, 1.0], integer = [true, false])","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"The elements of the vector can be:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"Vectors or arrays in general\nDictionaries\nStructs\nTuples\nNamedTuples\nNested data structures","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"Note that the use of vectors as elements is allowed. Similarly, the types of the lower and upper bounds and the initial values must be the same.","category":"page"},{"location":"problem/model/#Objective-definition","page":"Model definition","title":"Objective definition","text":"","category":"section"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To specify an objective function after creating the model, use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"set_objective!(model, obj)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"where obj is a function that takes a single vector argument. The vector input to obj will be of the same structure, shape and types as the initial solution, lower bound and upper bound vector.","category":"page"},{"location":"problem/model/#Inequality-constraint-definition","page":"Model definition","title":"Inequality constraint definition","text":"","category":"section"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To define an inequality constraint f(x) <= 0, where f is a Julia function that accepts a single input vector, use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"add_ineq_constraint!(model, f)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"The vector input to f will be of the same structure, shape and types as the initial solution, lower bound and upper bound vector. The function f can return:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"A number, in which case the constraint will be f(x) <= 0\nA vector or array of numbers, in which case the constraint will be applied element-wise f(x) .<= 0.\nAn arbitrary container or data structure, in which case the output will be vectorized first and the constraint will be applied element-wise on the vectorized output.","category":"page"},{"location":"problem/model/#Equality-constraint-definition","page":"Model definition","title":"Equality constraint definition","text":"","category":"section"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To define an inequality constraint f(x) == 0, where f is a Julia function that accepts a single input vector, use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"add_eq_constraint!(model, f)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"The vector input to f will be of the same structure, shape and types as the initial solution, lower bound and upper bound vector. The function f can return:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"A number, in which case the constraint will be f(x) == 0\nA vector or array of numbers, in which case the constraint will be applied element-wise f(x) .== 0.\nAn arbitrary container or data structure, in which case the output will be vectorized first and the constraint will be applied element-wise on the vectorized output.","category":"page"},{"location":"problem/model/#Changing-variable-bounds","page":"Model definition","title":"Changing variable bounds","text":"","category":"section"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"After defining the variables, it is possible to set the minimum and maximum variable bounds to different variables. This is useful for example in iterative procedures where the bounds are updated and the problem is resolved.","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To update the entire vector of minimum bounds, you can use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"setmin!(model, newmin)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"where newmin is a vector of bounds. -Inf is allowed in the bounds.","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To set a new minimum bound for the ith variable only, you can use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"setmin!(model, i, newmin)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"instead where newmin is a minimum bound of the appropriate type depending on the type of the ith variable.","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"Similarly, to update the entire vector of maximum bounds, you can use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"setmax!(model, newmax)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"where newmax is a vector of bounds. Inf is allowed in the bounds.","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To set a new maximum bound for the ith variable only, you can use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"setmax!(model, i, newmax)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"instead where newmax is a maximum bound of the appropriate type depending on the type of the ith variable.","category":"page"},{"location":"problem/model/#Changing-integrality-constraints","page":"Model definition","title":"Changing integrality constraints","text":"","category":"section"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"To constrain a variable to be integer or relax the integrality constraint on the ith variable, you can use:","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"setinteger!(model, i, integer)","category":"page"},{"location":"problem/model/","page":"Model definition","title":"Model definition","text":"where integer is true to constrain the variable or false to relax the constraint.","category":"page"},{"location":"gradients/implicit/#Implicit-differentiation","page":"Implicit differentiation","title":"Implicit differentiation","text":"","category":"section"},{"location":"gradients/implicit/#Background","page":"Implicit differentiation","title":"Background","text":"","category":"section"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"Differentiating implicit functions efficiently using the implicit function theorem has many applications including:","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"Nonlinear partial differential equation constrained optimization\nDifferentiable optimization layers in deep learning (aka deep declarative networks)\nDifferentiable fixed point iteration algorithms for optimal transport (e.g. the Sinkhorn methods)\nGradient-based bi-level and robust optimization (aka anti-optimization)\nMulti-parameteric programming (aka optimization sensitivity analysis)","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"For more on implicit differentation, refer to the last part of the Understanding automatic differentiation (in Julia) video on YouTube and the Efficient and modular implicit differentiation manuscript for an introduction to the methods implemented here.","category":"page"},{"location":"gradients/implicit/#Relationship-to-[ImplicitDifferentiation.jl](https://github.com/gdalle/ImplicitDifferentiation.jl)","page":"Implicit differentiation","title":"Relationship to ImplicitDifferentiation.jl","text":"","category":"section"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"ImplicitDifferentiation.jl is an attempt to simplify the implementation in Nonconvex making it more lightweight and better documented. For instance, the documentation of ImplicitDifferentiation presents a number of examples of implicit functions all of which can be defined using Nonconvex instead.","category":"page"},{"location":"gradients/implicit/#Explicit-parameters","page":"Implicit differentiation","title":"Explicit parameters","text":"","category":"section"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"There are 4 components to any implicit function:","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"The parameters p\nThe variables x\nThe residual f(p, x) which is used to define x(p) as the x which satisfies f(p, x) == 0 for a given value p\nThe algorithm used to evaluate x(p) satisfying the condition f(p, x) == 0","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"In order to define a differentiable implicit function using Nonconvex, you have to specify the \"forward\" algorithm which finds x(p). For instance, consider the following example:","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"using SparseArrays, NLsolve, Zygote, Nonconvex\n\nN = 10\nA = spdiagm(0 => fill(10.0, N), 1 => fill(-1.0, N-1), -1 => fill(-1.0, N-1))\np0 = randn(N)\n\nf(p, x) = A * x + 0.1 * x.^2 - p\nfunction forward(p)\n  # Solving nonlinear system of equations\n  sol = nlsolve(x -> f(p, x), zeros(N), method = :anderson, m = 10)\n  # Return the zero found (ignore the second returned value for now)\n  return sol.zero, nothing\nend","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"forward above solves for x in the nonlinear system of equations f(p, x) == 0 given the value of p. In this case, the residual function is the same as the function f(p, x) used in the forward pass. One can then use the 2 functions forward and f to define an implicit function using:","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"imf = ImplicitFunction(forward, f)\nxstar = imf(p0)","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"where imf(p0) solves the nonlinear system for p = p0 and returns the zero xstar of the nonlinear system. This function can now be part of any arbitrary Julia function differentiated by Zygote, e.g. it can be part of an objective function in an optimization problem using gradient-based optimization:","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"obj(p) = sum(imf(p))\ng = Zygote.gradient(obj, p0)[1]","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"In the implicit function's adjoint rule definition, the partial Jacobian ∂f/∂x is used according to the implicit function theorem. Often this Jacobian or a good approximation of it might be a by-product of the forward function. For example when the forward function does an optimization using a BFGS-based approximation of the Hessian of the Lagrangian function, the final BFGS approximation can be a good approximation of ∂f/∂x where the residual f is the gradient of the Lagrangian function wrt x. In those cases, this Jacobian by-product can be returned as the second argument from forward instead of nothing.","category":"page"},{"location":"gradients/implicit/#Implicit-parameters","page":"Implicit differentiation","title":"Implicit parameters","text":"","category":"section"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"In some cases, it may be more convenient to avoid having to specify p as an explicit argument in forward and f. The following is also valid to use and will give correct gradients with respect to p:","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"function obj(p)\n  N = length(p)\n  f(x) = A * x + 0.1 * x.^2 - p\n  function forward()\n    # Solving nonlinear system of equations\n    sol = nlsolve(f, zeros(N), method = :anderson, m = 10)\n    # Return the zero found (ignore the second returned value for now)\n    return sol.zero, nothing\n  end\n  imf = ImplicitFunction(forward, f)\n  return sum(imf())\nend\ng = Zygote.gradient(obj, p0)[1]","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"Notice that p was not an explicit argument to f or forward in the above example and that the implicit function is called using imf(). Using some explicit parameters and some implicit parameters is also supported.","category":"page"},{"location":"gradients/implicit/#Matrix-free-linear-solver-in-the-adjoint","page":"Implicit differentiation","title":"Matrix-free linear solver in the adjoint","text":"","category":"section"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"In the adjoint definition of implicit functions, a linear system:","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"(df/dy) * x = v","category":"page"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"is solved to find the adjoint vector. To solve the system using a matrix-free iterative solver (GMRES by default) that avoids constructing the Jacobian df/dy, you can set the matrixfree keyword argument to true (default is false). When set to false, the entrie Jacobian matrix is formed and the linear system is solved using LU factorization.","category":"page"},{"location":"gradients/implicit/#Arbitrary-data-structures","page":"Implicit differentiation","title":"Arbitrary data structures","text":"","category":"section"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"Both p and x above can be arbitrary data structures, not just arrays of numbers.","category":"page"},{"location":"gradients/implicit/#Tolerance","page":"Implicit differentiation","title":"Tolerance","text":"","category":"section"},{"location":"gradients/implicit/","page":"Implicit differentiation","title":"Implicit differentiation","text":"The implicit function theorem assumes that some conditions f(p, x) == 0 is satisfied. In practice, this will only be approximately satisfied. When this condition is violated, the gradient reported by the implicit function theorem cannot be trusted since its assumption is violated. The maximum tolerance allowed to \"accept\" the solution x(p) and the gradient is given by the keyword argument tol (default value is 1e-5). When the norm of the residual function f(p, x) is greater than this tolerance, NaNs  are returned for the gradient instead of the value computed via the implicit function theorem. If additionally, the keyword argument error_on_tol_violation is set to true (default value is false), an error is thrown if the norm of the residual exceeds the specified tolerance tol.","category":"page"},{"location":"problem/dict_model/#DictModel-definition","page":"DictModel definition","title":"DictModel definition","text":"","category":"section"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"There are 2 ways to define a DictModel. The direct method is:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"model = DictModel()","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"To pass an objective function while constructing the model, use:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"model = DictModel(obj)","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"where obj is a function that takes a single OrderedDict argument.","category":"page"},{"location":"problem/dict_model/#JuMP-model-to-Nonconvex-DictModel","page":"DictModel definition","title":"JuMP model to Nonconvex DictModel","text":"","category":"section"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"JuMP.jl has an excellent API for defining variables and linear constraints. Using JuMP makes it straightforward to copy a set of linear constraints and variable definitions from a paper. In Nonconvex, you can start with a JuMP model, define variables and constraints using JuMP's API then convert it to a DictModel. For example:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"jump_model = JuMP.Model()\n@variable jump_model 0 <= x[i=1:3] <= 1\n@constraint jump_model sum(x) <= 1\nmodel = DictModel(jump_model)","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"The objective can also be defined either using JuMP or Nonconvex. Once you convert the JuMP model to a Nonconvex model, you can go ahead and define more variables and constraints and/or set the objective in Nonconvex.","category":"page"},{"location":"problem/dict_model/#Variable-definition","page":"DictModel definition","title":"Variable definition","text":"","category":"section"},{"location":"problem/dict_model/#Add-a-single-variable","page":"DictModel definition","title":"Add a single variable","text":"","category":"section"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"Each variable in a DictModel has a name which can be a symbol or string. Each named variable can have an arbitrary type, e.g:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"Vectors or arrays in general\nDictionaries\nStructs\nTuples\nNamedTuples\nNested data structures","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"Vectorization and de-vectorization are handled automatically by Nonconvex.","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"To add a new named variable to a DictModel with a name :a and lower and upper bounds lb and ub respectively, use:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"addvar!(model, :a, lb, ub)","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"Similar to Model, optional keyword arguments init and integer can be set, and the types of the initial value, lb and ub must be the same.","category":"page"},{"location":"problem/dict_model/#Add-multiple-variables","page":"DictModel definition","title":"Add multiple variables","text":"","category":"section"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"There is no way to add multiple variables simultaneously to a DictModel however a single named variable that's a vector can be added.","category":"page"},{"location":"problem/dict_model/#Objective-definition","page":"DictModel definition","title":"Objective definition","text":"","category":"section"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"To specify an objective function after creating the model, use:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"set_objective!(model, obj)","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"where obj is a function that takes a single OrderedDict argument. The OrderedDict input to obj will be of the same structure, shape and types as the OrderedDict initial solution, lower bounds and upper bounds.","category":"page"},{"location":"problem/dict_model/#Inequality-constraint-definition","page":"DictModel definition","title":"Inequality constraint definition","text":"","category":"section"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"To define an inequality constraint f(x) <= 0, where f is a Julia function that accepts a single OrderedDict input, use:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"add_ineq_constraint!(model, f)","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"The OrderedDict input to f will be of the same structure, shape and types as the OrderedDict initial solution, lower bounds and upper bounds. The function f can return:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"A number, in which case the constraint will be f(x) <= 0\nA vector or array of numbers, in which case the constraint will be applied element-wise f(x) .<= 0.\nAn arbitrary container or data structure, in which case the output will be vectorized first and the constraint will be applied element-wise on the vectorized output.","category":"page"},{"location":"problem/dict_model/#Equality-constraint-definition","page":"DictModel definition","title":"Equality constraint definition","text":"","category":"section"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"To define an inequality constraint f(x) == 0, where f is a Julia function that accepts a single OrderedDict input, use:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"add_eq_constraint!(model, f)","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"The OrderedDict input to f will be of the same structure, shape and types as the OrderedDict initial solution, lower bounds and upper bounds. The function f can return:","category":"page"},{"location":"problem/dict_model/","page":"DictModel definition","title":"DictModel definition","text":"A number, in which case the constraint will be f(x) == 0\nA vector or array of numbers, in which case the constraint will be applied element-wise f(x) .== 0.\nAn arbitrary container or data structure, in which case the output will be vectorized first and the constraint will be applied element-wise on the vectorized output.","category":"page"},{"location":"algorithms/hyperopt/#Multi-start-and-hyper-parameter-optimization-in-pure-Julia","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"","category":"section"},{"location":"algorithms/hyperopt/#Description","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Description","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"Hyperopt.jl is a Julia library that implements a number of hyperparameter optimization algorithms which can be used to optimize the starting point of the optimization. NonconvexHyperopt.jl allows the use of the algorithms in Hyperopt.jl as meta-algorithms using the HyperoptAlg struct.","category":"page"},{"location":"algorithms/hyperopt/#Quick-start","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Quick start","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Hyperopt.","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"using Nonconvex\nNonconvex.@load Hyperopt\n\nalg = HyperoptAlg(IpoptAlg())\noptions = HyperoptOptions(sub_options = IpoptOptions(), sampler = GPSampler())\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"Hyperopt is an optional dependency of Nonconvex so you need to import it in order to use it. HyperoptAlg can wrap any other algorithm in Nonconvex, e.g. IpoptAlg(). When the algorithm is a HyperoptAlg, the options keyword argument must of type HyperoptOptions. For more on the options available see below.","category":"page"},{"location":"algorithms/hyperopt/#Construct-an-instance","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"To construct an instance of the Hyperopt + Ipopt algorithm, use:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"alg = HyperoptAlg(IpoptAlg())","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"HyperoptAlg can wrap any other algorithm in Nonconvex, e.g. NLoptAlg(:LD_MMA) or AugLag().","category":"page"},{"location":"algorithms/hyperopt/#Options","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Options","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"The options keyword argument to the optimize function shown above must be an instance of the HyperoptOptions struct when the algorihm is a HyperoptAlg. To specify options, use keyword arguments in the constructor of HyperoptOptions. The sampler keyword argument determines the sampling algorithm used to propose new starting points in the multi-start procedure. The sub_options keyword argument can be used to pass in the options for the sub-optimizer. There are 2 different ways to pass the sub-options depending on the sampler type.","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"The sampler argument can be of type:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"RandomSampler\nLHSampler\nCLHSampler\nGPSampler\nHyperband","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"When optimizing the starting point, the upper and lower bounds on the initial solution must be finite, or finite bounds must be passed in to the options constructor. All the options that can be passed to the HyperoptOptions constructor are listed below:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"NonconvexMultistart.HyperoptOptions","category":"page"},{"location":"algorithms/hyperopt/#NonconvexMultistart.HyperoptOptions","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"NonconvexMultistart.HyperoptOptions","text":"HyperoptOptions: options performing starting point optimization using Hyperopt.jl\n\nsub_options: options for the sub-optimizer.\nlb: Lower bound of starting point, if don't specify it, the default value will be nothing,            then will end up be replaced by the lower bound of optimization problem.\nub: Upper bound of starting point, same as above. \nsearchspace_size::Integer: How many potential starting points we generate.\niters::Integer: Among all generated potential starting points, how many of them will be evaluated. \nsampler::Hyperopt.Sampler: An instance of 'Hyperopt.Sampler', which decides search algorithm. \nctol: infeasibility tolerance for accepting a solution as feasible\nkeep_all: if true, all the solutions of the sub-problems will be saved\n\n\n\n\n\n","category":"type"},{"location":"algorithms/hyperopt/#Sampler-choice","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Sampler choice","text":"","category":"section"},{"location":"algorithms/hyperopt/#RandomSampler,-LHSampler,-CLHSampler-and-GPSampler","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"RandomSampler, LHSampler, CLHSampler and GPSampler","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"All the sampler constructors are functions defined in Nonconvex wrapping the Hyperopt alternatives to define defaults. For GPSampler, Hyperopt.Min is always used by default in Nonconvex so you should not pass this argument. All the other arguments that can be passed to the sampler constructor can be found in the Hyperopt documentation. Example:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"options = HyperoptOptions(sub_options = IpoptOptions(), sampler = GPSampler())","category":"page"},{"location":"algorithms/hyperopt/#Hyperband","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Hyperband","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"The Hyperband algorithm in Hyperopt requires a different way to pass in the sub-options. The Hyperband algorithm tries to optimize the allocation of resources. The sub_options argument must be a function with input as the \"resources\" and output as the sub-solver options. The Hyperband constructor accepts 3 arguments:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"The maximum resources R\nη which roughly determines the proportion of trials discarded between each round of successive halving\ninner which specifies an inner sampler of type RandomSampler, LHSampler or CLHSampler.","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"Example:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start and hyper-parameter optimization in pure Julia","title":"Multi-start and hyper-parameter optimization in pure Julia","text":"options = HyperoptOptions(\n    sub_options = max_iter -> IpoptOptions(max_iter = max_iter), \n    sampler = Hyperband(R=100, η=3, inner=RandomSampler()),\n)","category":"page"},{"location":"algorithms/minlp/#First-and-second-order-mixed-integer-nonlinear-programming-algorithms","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"","category":"section"},{"location":"algorithms/minlp/#Description","page":"First and second order mixed integer nonlinear programming algorithms","title":"Description","text":"","category":"section"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"There are 2 first and second order MINLP solvers available in Nonconvex:","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"Juniper.jl with Ipopt.jl as a sub-solver. NonconvexJuniper.jl allows the use of the branch and bound algorithm in Juniper.jl using the JuniperIpoptAlg struct.\nPavito.jl with Ipopt.jl and Cbc.jl as sub-solvers. NonconvexPavito.jl allows the use of the sequential polyhedral outer-approximations algorithm in Pavito.jl using the PavitoIpoptCbcAlg struct.","category":"page"},{"location":"algorithms/minlp/#Juniper-Ipopt","page":"First and second order mixed integer nonlinear programming algorithms","title":"Juniper + Ipopt","text":"","category":"section"},{"location":"algorithms/minlp/#Quick-start","page":"First and second order mixed integer nonlinear programming algorithms","title":"Quick start","text":"","category":"section"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Juniper and Ipopt.","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"using Nonconvex\nNonconvex.@load Juniper\n\nalg = JuniperIpoptAlg()\noptions = JuniperIpoptOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"Juniper is an optional dependency of Nonconvex, so you need to load it in order to use it. Note that the integer constraints must be specified when defining variables. See the problem definition documentation for more details.","category":"page"},{"location":"algorithms/minlp/#Construct-an-instance","page":"First and second order mixed integer nonlinear programming algorithms","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"To construct an instance of the Juniper + Ipopt algorithm, use:","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"alg = JuniperIpoptAlg()","category":"page"},{"location":"algorithms/minlp/#Options","page":"First and second order mixed integer nonlinear programming algorithms","title":"Options","text":"","category":"section"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"The options keyword argument to the optimize function shown above must be an instance of the JuniperIpoptOptions struct when the algorihm is a JuniperIpoptAlg. To specify options use, keyword arguments in the constructor of JuniperIpoptOptions, e.g:","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"options = JuniperIpoptOptions(first_order = false, linear_constraints = true, subsolver_options = IpoptOptions(), atol = 1e-4)","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"There are 3 important and special options you can pass to the optimizer:","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"first_order: true by default. When first_order is true, the first order Ipopt algorithm will be used. And when it is false, the second order Ipopt algorithm will be used.\nlinear_constraints: false by default. When linear_constraints is true, the Jacobian of the constraints will be computed and sparsified once at the beginning. When it is false, dense Jacobians will be computed in every iteration.\nsubsolver_options: an instance of IpoptOptions to be used in the Ipopt sub-solver.","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"All the other options to Juniper can be found in the Juniper documentation.","category":"page"},{"location":"algorithms/minlp/#Pavito-Ipopt-Cbc","page":"First and second order mixed integer nonlinear programming algorithms","title":"Pavito + Ipopt + Cbc","text":"","category":"section"},{"location":"algorithms/minlp/#Quick-start-2","page":"First and second order mixed integer nonlinear programming algorithms","title":"Quick start","text":"","category":"section"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Juniper and Ipopt.","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"using Nonconvex\nNonconvex.@load Pavito\n\nalg = PavitoIpoptCbcAlg()\noptions = PavitoIpoptCbcOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"Pavito is an optional dependency of Nonconvex, so you need to load it in order to use it. Note that the integer constraints must be specified when defining variables. See the problem definition documentation for more details.","category":"page"},{"location":"algorithms/minlp/#Construct-an-instance-2","page":"First and second order mixed integer nonlinear programming algorithms","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"To construct an instance of the Pavito + Ipopt + Cbc algorithm, use:","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"alg = PavitoIpoptCbcAlg()","category":"page"},{"location":"algorithms/minlp/#Options-2","page":"First and second order mixed integer nonlinear programming algorithms","title":"Options","text":"","category":"section"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"The options keyword argument to the optimize function shown above must be an instance of PavitoIpoptCbcOptions struct when the algorithm is a PavitoIpoptCbcAlg. To specify options, use keyword arguments in the constructor of JuniperIpoptOptions or PavitoIpoptCbcOptions, e.g:","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"options = PavitoIpoptCbcOptions(first_order = false, subsolver_options = IpoptOptions(), timeout = 120.0)","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"There are 2 important and special options you can pass to the optimizer:","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"first_order: true by default. When first_order is true, the first order Ipopt algorithm will be used. And when it is false, the second order Ipopt algorithm will be used.\nsubsolver_options: an instance of IpoptOptions to be used in the Ipopt sub-solver.","category":"page"},{"location":"algorithms/minlp/","page":"First and second order mixed integer nonlinear programming algorithms","title":"First and second order mixed integer nonlinear programming algorithms","text":"All the other options to Pavito can be found in the Pavito documentation.","category":"page"},{"location":"algorithms/nomad/#Nonlinear-optimization-with-the-MADS-(NOMAD)-algorithm-for-continuous-and-discrete,-constrained-optimization","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"","category":"section"},{"location":"algorithms/nomad/#Description","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Description","text":"","category":"section"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"NOMAD.jl is an optimization package wrapping the C++ implementation of the NOMAD algorithm. NonconvexNOMAD allows the use of NOMAD.jl using the the NOMADAlg struct. NOMAD.jl supports continuous and integer decision variables as well as bounds and inequality constraints. Linear equality constraints are also supported when no integer decision variables are in the model.","category":"page"},{"location":"algorithms/nomad/#Quick-start","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Quick start","text":"","category":"section"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using NOMAD.","category":"page"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"using Nonconvex\nNonconvex.@load NOMAD\n\nalg = NOMADAlg()\noptions = NOMADOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"NOMAD is an optional dependency of Nonconvex so you need to load the package to be able to use it.","category":"page"},{"location":"algorithms/nomad/#Algorithm-types","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Algorithm types","text":"","category":"section"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"There are 3 different variants of the NOMADAlg struct:","category":"page"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"NOMADAlg(:explicit)\nNOMADAlg(:progressive)\nNOMADAlg(:custom)","category":"page"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"The explicit algorithm ensures all the constraints are satisfied at all times removing any infeasible point from the population. The progressive algorithm allows infeasible points to be part of the population but enforces feasibility in a progressive manner. The custom variant allows the use of flags on each constraint to declare it as :explicit or :progressive. For instance, assume model is the Nonconvex model and g1 and g2 are 2 constraint functions.","category":"page"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"add_ineq_constraint!(model, g1, flags = [:explicit])\nadd_ineq_constraint!(m, g2, flags = [:progressive])","category":"page"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"The above code declares the first constraint as explicit and the second as progressive. In other words, every point violating the first constraint will be removed from the population but the second constraint will be more progressively enforced.","category":"page"},{"location":"algorithms/nomad/#Options","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Options","text":"","category":"section"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"The options keyword argument to the optimize function shown above must be an instance of the NOMADOptions struct when the algorihm is a NOMADAlg. To specify options use keyword arguments in the constructor of NOMADOptions, e.g:","category":"page"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"options = NOMADOptions()","category":"page"},{"location":"algorithms/nomad/","page":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","title":"Nonlinear optimization with the MADS (NOMAD) algorithm for continuous and discrete, constrained optimization","text":"All the options that can be set can be found in the NOMAD.jl documentation.","category":"page"},{"location":"algorithms/auglag/#Augmented-Lagrangian-algorithm-in-pure-Julia","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"","category":"section"},{"location":"algorithms/auglag/#Description","page":"Augmented Lagrangian algorithm in pure Julia","title":"Description","text":"","category":"section"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"Percival.jl is a pure Julia implementation of the augmented Lagrangian algorithm. Both first and second order versions of the algorithm are available.","category":"page"},{"location":"algorithms/auglag/#Quick-start","page":"Augmented Lagrangian algorithm in pure Julia","title":"Quick start","text":"","category":"section"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Percival.","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"using Nonconvex\nNonconvex.@load Percival\n\nalg = AugLag()\noptions = AugLagOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"Percival is an optional dependency of Nonconvex so you need to import it in order to use it.","category":"page"},{"location":"algorithms/auglag/#Construct-an-instance","page":"Augmented Lagrangian algorithm in pure Julia","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"To construct an instance of the Ipopt algorithm, use:","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"alg = AugAlg()","category":"page"},{"location":"algorithms/auglag/#Options","page":"Augmented Lagrangian algorithm in pure Julia","title":"Options","text":"","category":"section"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"The options keyword argument to the optimize function shown above must be an instance of the AugLagOptions struct when the algorihm is an AugLag. To specify options use keyword arguments in the constructor of AugLagOptions, e.g:","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"options = AugLagOptions(first_order = false, rtol = 1e-4)","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"The most important option is first_order which is true by default. When first_order is true, the first order augmented Lagrangian algorithm will be used. And when it is false, the second order augmented Lagrangian algorithm will be used. Other arguments include:","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"atol: absolute tolerance in the subproblem optimizer\nrtol: relative tolerance in the subproblem optimizer\nctol: absolute feasibility tolerance\nmax_iter: maximum number of iterations\nmax_time: maximum time in seconds\nmax_eval: maximum number of function evaluations","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm in pure Julia","title":"Augmented Lagrangian algorithm in pure Julia","text":"When using the first order augmented Lagrangian and a block constraint (i.e. a constraint function that returns a vector), the use of reverse-mode AD will only require calling the adjoint operator of the block constraint function in order to compute the gradient of the augmented Lagrangian. This is particularly suitable for constraint functions whose Jacobians are expensive but the adjoint operator is relatively inexpensive.","category":"page"},{"location":"algorithms/ipopt/#Interior-point-method-using-Ipopt.jl","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"","category":"section"},{"location":"algorithms/ipopt/#Description","page":"Interior point method using Ipopt.jl","title":"Description","text":"","category":"section"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"Ipopt is a well known interior point optimizer developed and maintained by COIN-OR. The Julia wrapper of Ipopt is Ipopt.jl. Ipopt.jl is wrapped in NonconvexIpopt.jl. NonconvexIpopt allows the use of Ipopt.jl using the IpoptAlg algorithm struct. IpoptAlg can be used as a second order optimizer computing the Hessian of the Lagrangian in every iteration. Alternatively, an l-BFGS approximation of the Hessian can be used instead turning IpoptAlg into a first order optimizer tha only requires the gradient of the Lagrangian.","category":"page"},{"location":"algorithms/ipopt/#Quick-start","page":"Interior point method using Ipopt.jl","title":"Quick start","text":"","category":"section"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Ipopt.","category":"page"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"using Nonconvex\nNonconvex.@load Ipopt\n\nalg = IpoptAlg()\noptions = IpoptOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/ipopt/#Construct-an-instance","page":"Interior point method using Ipopt.jl","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"To construct an instance of the Ipopt algorithm, use:","category":"page"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"alg = IpoptAlg()","category":"page"},{"location":"algorithms/ipopt/#Options","page":"Interior point method using Ipopt.jl","title":"Options","text":"","category":"section"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"The options keyword argument to the optimize function shown above must be an instance of the IpoptOptions struct when the algorihm is an IpoptAlg. To specify options use keyword arguments in the constructor of IpoptOptions, e.g:","category":"page"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"options = IpoptOptions(first_order = false, tol = 1e-4, sparse = false, symbolic = false)","category":"page"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"There are 4 important and special options:","category":"page"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"first_order: true by default. When first_order is true, the first order Ipopt algorithm will be used. And when it is false, the second order Ipopt algorithm will be used.\nsymbolic: false by default. When symbolic is set to true, the gradients, Jacobians and Hessians of the objective, constraint and Lagrangian functions will be calculated using symbolic differentiation from Symbolics.jl. This is the same approach used by symbolify which is described in the symbolic differentiation section in the documentation.\nsparse: false by default. When sparse is set to true, the gradients, Jacobians and Hessians of the objective, constraint and Lagrangian functions will be treated as sparse vectors/matrices. When combined with symbolic = true, the output of symbolic differentiation will be a sparse vector/matrix, akin to setting sparse = true in the symbolify function discussed in symbolic differentiation section in the documentation. When used alone with symbolic = false, SparseDiffTools.jl is used instead for the differentiation and Symbolics is only used to get the sparsity pattern, much like how sparsify works. For more details on sparsify and the way SparseDiffTools works, see the sparsity section in the documentation is used instead.\nlinear_constraints:  false by default. When linear_constraints is true, the Jacobian of the constraints will be computed and sparsified once at the beginning. When it is false, dense Jacobians will be computed in every iteration.","category":"page"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"Note that there is no need to use sparsify or symbolify on the model or functions before optimizing it with an IpoptAlg. Setting the sparse and symbolic options above are enough to trigger the symbolic differentiation and/or sparsity exploitation.","category":"page"},{"location":"algorithms/ipopt/","page":"Interior point method using Ipopt.jl","title":"Interior point method using Ipopt.jl","text":"All the other options that can be set can be found on the Ipopt options section of Ipopt's documentation.","category":"page"},{"location":"gradients/user_defined/#User-defined-gradient,-Jacobian-or-Hessian","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"","category":"section"},{"location":"gradients/user_defined/#Gradients-and-Jacobians","page":"User-defined gradient, Jacobian or Hessian","title":"Gradients and Jacobians","text":"","category":"section"},{"location":"gradients/user_defined/","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"To use a user-defined gradient/Jacobian function g(x) for a function f(x), you can use the CustomGradFunction modifier:","category":"page"},{"location":"gradients/user_defined/","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"F = CustomGradFunction(f, g)\nF(x)","category":"page"},{"location":"gradients/user_defined/","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"F can be then used in place of f as an objective function, as a constraint function or as part of any such function. When f is scalar-valued, g is expected to return a gradient vector. When f is vector-valued, g is expected to return a Jacobian matrix. Whenever ForwardDiff or any ChainRules-compatible AD package such as Zygote is used to differentiate F, the custom gradient/Jacobian function g will be used.","category":"page"},{"location":"gradients/user_defined/#Hessian-or-Hessian-vector-product","page":"User-defined gradient, Jacobian or Hessian","title":"Hessian or Hessian vector product","text":"","category":"section"},{"location":"gradients/user_defined/","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"For second-order optimization algorithms, a user-defined Hessian function h(x) can be used for any scalar-valued function f(x) with gradient g(x). To use a user-defined Hessian function h(x), you can use the CustomHessianFunction modifier:","category":"page"},{"location":"gradients/user_defined/","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"F = CustomHessianFunction(f, g, h)\nF(x)","category":"page"},{"location":"gradients/user_defined/","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"F can be then used in place of f as an objective function, as a constraint function or as part of any such function. f is expected to return a scalar, g is expected to return a gradient vector and h is expected to return a symmetric Hessian matrix. Whenever ForwardDiff or any ChainRules-compatible AD package such as Zygote is used to differentiate F, the custom gradient and Hessian functions will be used.","category":"page"},{"location":"gradients/user_defined/","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"Instead of a Hessian function h, alternatively a Hessian-vector product operator h(x, v) can be used, which multiplies the Hessian of f at x by the vector v. To use a Hessian-vector product operator hvp(x, v) instead of computing the full Hessian, you can pass the hvp function as the third argument to CustomHessianFunction and set the hvp keyword argument to true:","category":"page"},{"location":"gradients/user_defined/","page":"User-defined gradient, Jacobian or Hessian","title":"User-defined gradient, Jacobian or Hessian","text":"F = CustomHessianFunction(f, g, hvp; hvp = true)\nF(x)","category":"page"},{"location":"algorithms/mts/#Multi-trajectory-search-algorithm-in-pure-Julia","page":"Multi-trajectory search algorithm in pure Julia","title":"Multi-trajectory search algorithm in pure Julia","text":"","category":"section"},{"location":"algorithms/mts/#Description","page":"Multi-trajectory search algorithm in pure Julia","title":"Description","text":"","category":"section"},{"location":"algorithms/mts/","page":"Multi-trajectory search algorithm in pure Julia","title":"Multi-trajectory search algorithm in pure Julia","text":"Multiple trajectory search (MTS) is a derivative-free heuristic optimization method presented by Lin-Yu Tseng and Chun Chen, 2008.  The MTS algorithm is implemented in the NonconvexSearch.jl package. This module implements all the optimization methods in the paper.","category":"page"},{"location":"algorithms/mts/#Quick-start","page":"Multi-trajectory search algorithm in pure Julia","title":"Quick start","text":"","category":"section"},{"location":"algorithms/mts/","page":"Multi-trajectory search algorithm in pure Julia","title":"Multi-trajectory search algorithm in pure Julia","text":"Using default MTSOptions(). MTS is used for optimization. ","category":"page"},{"location":"algorithms/mts/","page":"Multi-trajectory search algorithm in pure Julia","title":"Multi-trajectory search algorithm in pure Julia","text":"using Nonconvex\nNonconvex.@load MTS\n\nalg = MTSAlg()\nLS1_options = MTSOptions()\nm = Model(f)\nlb = [0, 0]\nub = [5, 5]\naddvar!(m, lb, ub)\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"gradients/sparse/#Sparse-Jacobian-or-Hessian","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"","category":"section"},{"location":"gradients/sparse/#Background","page":"Sparse Jacobian or Hessian","title":"Background","text":"","category":"section"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"For functions with a sparse Jacobian or Hessian, it can sometimes be useful to exploit such sparsity to speedup the computation of the Jacobian. This can be done using the SparseDiffTools.jl package.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"SparseDiffTools can compute multiple columns of the Jacobian matrix of a vector-valued function y = f(x) simulatenously using a single Jacobian-vector product operation. Such columns corresponding to a subset of the input variables, e.g. (x[1], x[3]), however need not overlap in the output variables they influence. For instance, assume","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"y[1] and y[2] are a function of x[1] and x[2] only, and\ny[3] and y[4] are a function of x[3] and x[4] only.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"The Jacobian dy/dx will therefore have a block diagonal structure. Additionally, since x[1] and x[3] do not affect the same output variables, their corresponding columns in the block-diagonal Jacobian can be computed simulatenously using a single Jacobian-vector block. The same thing for x[2] and x[4]. Finding such subsets of input variables such that no 2 input variables in a subset affect the same output is done using SparseDiffTools. In the diagonal Jacobian case, all the input variables do not overlap so all the columns of the Jacobian can be obtained using a single Jacobian-vector product.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"The problem of finding the optimal splitting of input variables to require the least number of Jacobian-vector products when computing the full Jacobian can be formulated as a graph coloring problem in computer science, which is an NP-hard problem. SparseDiffTools uses a tractable heuristic to find reasonable splittings for different Jacobian or Hessian sparsity patterns. The sparsity pattern of the Jacobian or Hessian can either be user-provided or it will be automatically uncovered using Symbolics.jl.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"In Nonconvex, you can enforce the use of SparseDiffTools for specific functions using the sparsify function modifier. In particular, the rrule and frule of the modified function will be using SparseDiffTools to find the full Jacobian first and then doing either a Jacobian-vector product in the frule or a vector-Jacobian product in the rrule. Such frule will also be used by ForwardDiff if used to differentiate the modified function. For more on frules, rrules, Jacobian-vector products and vector-Jacobian products, refer to the following video on Understanding autmoatic differentiation (in Julia).","category":"page"},{"location":"gradients/sparse/#Sparsifying-a-function","page":"Sparse Jacobian or Hessian","title":"Sparsifying a function","text":"","category":"section"},{"location":"gradients/sparse/#First-order-derivatives","page":"Sparse Jacobian or Hessian","title":"First order derivatives","text":"","category":"section"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"In order to force Nonconvex to use SparseDiffTools when differentiating a function f(x...) once, the sparsify function modifier can be used:","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"F = sparsify(f, x...; hessian = false)\nF(x...)","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"where x is some sample input arguments to f. F(x...) can now be used inplace of f(x...) in objectives and/or constraints to be differentiated. Whenever ForwardDiff or any ChainRules-compatible AD package such as Zygote is used to differentiate F once, SparseDiffTools will now be used.","category":"page"},{"location":"gradients/sparse/#Second-order-derivatives","page":"Sparse Jacobian or Hessian","title":"Second order derivatives","text":"","category":"section"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"When hessian = false (the default value), only the Jacobian/gradient of F will be treated as sparse. In order to use SparseDiffTools to compute sparse second order derivatives as well, you can set hessian = true. This is recommended for scalar-valued functions with sparse Hessian matrices. Setting hessian = true will also work for vector-valued functions f or for functions f that return multiple, non-vector outputs. The sparsity of the third order derivative tensor will be used to compute the third order tensor efficiently.","category":"page"},{"location":"gradients/sparse/#User-defined-sparsity-patterns","page":"Sparse Jacobian or Hessian","title":"User-defined sparsity patterns","text":"","category":"section"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"Using sparsify as shown above will make use of Symbolics to uncover the sparsity of the Jacobian and Hessian matrices of f. In some cases, the function f may not be Symbolics-compatible or it may have a known sparsity pattern. The user can therefore use the jac_pattern or hess_pattern keyword arguments to set the pattern manually.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"The jac_pattern is expected to be a SparseMatrixCSC of element type Bool with true where there is a structural non-zero, and false where there is a structural zero in the Jacobian matrix. The size of jac_pattern should be noutputs x ninputs where noutputs is the number of outputs of f and ninputs is the number of inputs to f. When the inputs and/or outputs are multiple and/or non-vector, they are assumed to be flattened to vectors and noutputs/ninputs is the length of the flat vector.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"Passing the Hessian sparsity pattern is also possible using the hess_pattern keyword argument. For scalar-valued functions, hess_pattern should have size ninputs x ninputs where ninputs is the number of input variables in the flattened input arguments. For vector-valued functions, the sparsity pattern will be the sparsity pattern of the Jacobian of the linearized Jacobian of f. Assume f takes a single vector input x and returns a single output vector y. The sparsity pattern will be that of d(vec(dy/dx))/dx. hess_pattern should therefore have size (noutputs * ninputs) x ninputs. For example, assume y is a vector of length 2 and x is a vector of length 3. The Jacobian dy/dx will be a matrix of size 2 x 3. vec(dy/dx) will be a vector of length 6. d(vec(dy/dx))/dx will be a matrix of size 6 x 3. hess_pattern should therefore be a SparseMatrixCSC with element type Bool and size 6 x 3.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"For general functions f with multiple or non-vector inputs or outputs, noutputs and ninputs are the lengths of the flattened outputs and inputs respectively.","category":"page"},{"location":"gradients/sparse/#Sparsifying-a-model","page":"Sparse Jacobian or Hessian","title":"Sparsifying a model","text":"","category":"section"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"Instead of sparsifying one function at a time, the user can instead sparsify an entire Nonconvex model including the objective, all the inequality constraint functions, all the equality constraint functions and all the semidefinite constraint functions.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"sp_model = sparsify(model, hessian = true)","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"where model is of type Model or DictModel and hessian has the same intepretation from the function sparisfication above. sp_model can now be optimized using any of the Nonconvex algorithms compatible with the model.","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"By default, the objective and all the constraint functions will be sparsified. To prevent the sparisfication of some component of the model, any of the following keyword arguments can be set to false (default is true):","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"objective = false\nineq_constraints = false\neq_constraints = false\nsd_constraints = false","category":"page"},{"location":"gradients/sparse/","page":"Sparse Jacobian or Hessian","title":"Sparse Jacobian or Hessian","text":"Setting the objective, ineq_constraints, eq_constraints, and/or sd_constraints keyword arguments to false (default is true) will prevent the sparisification of the objective, all the inequality constraint functions, all the equality constraint functions, and/or all the semidefinite constraint functions respectively.","category":"page"},{"location":"algorithms/tobs/#Topology-optimization-of-binary-structures-(TOBS),-a-nonlinear-binary-optimization-heuristic","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"","category":"section"},{"location":"algorithms/tobs/#Description","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Description","text":"","category":"section"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"The method of topology optimization of binary structures (TOBS) was originally developed in the context of optimal distribution of material in mechanical components. The TOBS algorithm only supports binary decision variables. The TOBS algorithm is a heuristic that relies on the sequential linearization of the objective and constraint functions, progressively enforcing the constraints in the process. The resulting binary linear program can be solved using any mixed integer linear programming (MILP) solver such Cbc. This process is repeated iteratively until convergence. This package implements the heuristic for binary nonlinear programming problems.","category":"page"},{"location":"algorithms/tobs/#Construct-an-instance","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"To construct an instance of the TOBS algorithm, use:","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"alg = TOBSAlg()","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"When optimizing a model using TOBSAlg, all the variables are assumed to be binary if their lower and upper bounds are 0 and 1 respectively even if the isinteger flag was not used. If there are variables with other bounds' values, the optimization will give an error.","category":"page"},{"location":"algorithms/tobs/#Example","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Example","text":"","category":"section"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"In this example, the classic topology optimization problem of minimizing the compliance of the structure subject to a volume constraint. Begin by installing and loading the packages required.","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"import Nonconvex\nNonconvex.@load TOBS\nusing Pkg\nPkg.add(\"TopOpt\")\nusing TopOpt","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"Define the problem and its parameters using TopOpt.jl.","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"E = 1.0 # Young’s modulus\nv = 0.3 # Poisson’s ratio\nf = 1.0 # downward force\nrmin = 6.0 # filter radius\nxmin = 0.001 # minimum density\nV = 0.5 # maximum volume fraction\np = 3.0 # SIMP penalty\n\n# Define FEA problem\nproblem_size = (160, 100) # size of rectangular mesh\nx0 = fill(1.0, prod(problem_size)) # initial design\nproblem = PointLoadCantilever(Val{:Linear}, problem_size, (1.0, 1.0), E, v, f)\nsolver = FEASolver(Direct, problem; xmin=xmin)\nTopOpt.setpenalty!(solver, p)\ncheqfilter = DensityFilter(solver; rmin=rmin) # filter function\ncomp = TopOpt.Compliance(problem, solver) # compliance function","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"Define the objective and constraint functions.","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"obj(x) = comp(cheqfilter(x)) # compliance objective\nconstr(x) = sum(cheqfilter(x)) / length(x) - V # volume fraction constraint","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"Finally, define the optimization problem using Nonconvex.jl and optimize it.","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"m = Model(obj)\naddvar!(m, zeros(length(x0)), ones(length(x0)))\nNonconvex.add_ineq_constraint!(m, constr)\noptions = TOBSOptions()\n\nr = optimize(m, TOBSAlg(), x0; options=options)\nr.minimizer\nr.minimum","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"The following is a visualization of the optimization history using this example.","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"(Image: histories)","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"(Image: gif)","category":"page"},{"location":"algorithms/tobs/#Options","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Options","text":"","category":"section"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"The following are the options that can be set by passing them to TOBSOptions, e.g. TOBSOptions(movelimit = 0.1).","category":"page"},{"location":"algorithms/tobs/","page":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","title":"Topology optimization of binary structures (TOBS), a nonlinear binary optimization heuristic","text":"movelimit: the maximum move limit in each iteration as a ratio of the total number of variables. Default value is 0.1, i.e. a maximum of 10% of the variables are allowed to flip value in each iteration.\nconvParam: the tolerance value. The algrotihm is said to have converged if the moving average of the relative change in the objective value in the last pastN iterations is less than convParam. Default value is 0.001.\npastN: the number of past iterations used to compute the moving average of the relative change in the objective value. Default value is 20.\nconstrRelax: the amount of constraint relaxation applied to the linear approximation in each iteration. This is the relative constraint relaxation if the violation is higher than constrRelax and the absolute constraint relaxation otherwise. Default value is 0.1.\ntimeLimit: the time limit (in seconds) of each MILP solve for the linearized sub-problem. Default value is 1.0.\noptimizer: the JuMP optimizer type used to solve the MILP sub-problem. Default value is Cbc.Optimizer.\nmaxiter: the maximum number of iterations for the algorithm. Default value is 200.\ntimeStable: a boolean value that when set to true switches on the time stability filter of the objective's gradient, discussed in the paper. Default value is true.","category":"page"},{"location":"gradients/symbolic/#Symbolic-differentiation","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"","category":"section"},{"location":"gradients/symbolic/#Background","page":"Symbolic differentiation","title":"Background","text":"","category":"section"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"For functions, a tractable symbolic gradient/Jacobian/Hessian may exist. Symbolics.jl is a symbolic mathematics package in Julia that can uncover the mathematical expression from Julia functions and then symbolically differentiate the resulting expression. Symbolic simplifications and cancellations can sometimes lead to computational savings compared to algorithmic differentiation. Symbolic differentiation can further exploit the sparsity of the graident, Jacobian and/Hessian if one exists.","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"In Nonconvex, you can enforce the use of Symbolics to symbolically differentiate specific functions using the symbolify function modifier. In particular, the Symbolics-derived gradient/Jacobian/Hessian functions will be used whenever ForwardDiff or any ChainRules-compatible AD package such as Zygote is used to differentiate the modified function.","category":"page"},{"location":"gradients/symbolic/#Symbolifying-a-function","page":"Symbolic differentiation","title":"Symbolifying a function","text":"","category":"section"},{"location":"gradients/symbolic/#First-order-derivatives","page":"Symbolic differentiation","title":"First order derivatives","text":"","category":"section"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"In order to force Nonconvex to use Symbolics when differentiating a function f(x...) once, the symbolify function modifier can be used:","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"F = symbolify(f, x...; hessian = false, sparse = false, simplify = false)\nF(x...)","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"where x is some sample input arguments to f. F(x...) can now be used inplace of f(x...) in objectives and/or constraints to be differentiated. Whenever ForwardDiff or any ChainRules-compatible AD package such as Zygote is used to differentiate F once, the Symbolics-derived gradient/Jacobian will now be used.","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"The sparse keyword argument can be set to true (default is false) to tell Symbolics to return a sparse gradient/Jacobian for the function F. The simplify keyword argument can be set to true (default is false) to tell Symbolics to simplify the mathematical expressions for the gradient/Jacobian functions.","category":"page"},{"location":"gradients/symbolic/#Second-order-derivatives","page":"Symbolic differentiation","title":"Second order derivatives","text":"","category":"section"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"When hessian = false (the default value), only the Jacobian/gradient of F will be computed with Symbolics. In order to use Symbolics to differentiate the function F twice, you can set hessian = true. Setting hessian = true will also work for vector-valued functions f or for functions f that return multiple, non-vector outputs. The sparse and simplify keyword arguments work the same way when hessian is set to true.","category":"page"},{"location":"gradients/symbolic/#Symbolifying-a-model","page":"Symbolic differentiation","title":"Symbolifying a model","text":"","category":"section"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"Instead of symbolifying one function at a time, the user can instead symbolify an entire Nonconvex model including the objective, all the inequality constraint functions, all the equality constraint functions and all the semidefinite constraint functions.","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"sym_model = symbolify(model, hessian = true, simplify = true, sparse = true)","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"where model is of type Model or DictModel and hessian, simplify and sparse have the same intepretation from the function symbolification above. sym_model can now be optimized using any of the Nonconvex algorithms compatible with the model.","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"By default, the objective and all the constraint functions will be symbolified. To prevent the symbolification of some component of the model, any of the following keyword arguments can be set to false (default is true):","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"objective = false\nineq_constraints = false\neq_constraints = false\nsd_constraints = false","category":"page"},{"location":"gradients/symbolic/","page":"Symbolic differentiation","title":"Symbolic differentiation","text":"Setting the objective, ineq_constraints, eq_constraints, and/or sd_constraints keyword arguments to false (default is true) will prevent the symbolification of the objective, all the inequality constraint functions, all the equality constraint functions, and/or all the semidefinite constraint functions respectively.","category":"page"},{"location":"algorithms/nlopt/#Various-optimization-algorithms-from-NLopt.jl","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"","category":"section"},{"location":"algorithms/nlopt/#Description","page":"Various optimization algorithms from NLopt.jl","title":"Description","text":"","category":"section"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"NLopt is an optimization library with a collection of optimization algorithms implemented. NLopt.jl is the Julia wrapper of NLopt. NonconvexNLopt allows the use of NLopt.jl using the NLoptAlg algorithm struct.","category":"page"},{"location":"algorithms/nlopt/#Quick-start","page":"Various optimization algorithms from NLopt.jl","title":"Quick start","text":"","category":"section"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using NLopt.","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"using Nonconvex\nNonconvex.@load NLopt\n\nalg = NLoptAlg(:LD_SLSQP)\noptions = NLoptOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"NLopt is an optional dependency of Nonconvex so you need to load the package to be able to use it.","category":"page"},{"location":"algorithms/nlopt/#Construct-an-instance","page":"Various optimization algorithms from NLopt.jl","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"To construct an instance of NLopt's NLOPT_LD_SLSQP algorithm, use:","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"alg = NLoptAlg(:LD_SLSQP)","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"All the algorithms available in NLopt are:","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":":GN_DIRECT\n:GN_DIRECT_L\n:GNL_DIRECT_NOSCAL\n:GN_DIRECT_L_NOSCAL\n:GN_DIRECT_L_RAND_NOSCAL\n:GN_ORIG_DIRECT\n:GN_ORIG_DIRECT_L\n:GN_CRS2_LM\n:G_MLSL_LDS\n:G_MLSL\n:GD_STOGO\n:GD_STOGO_RAND\n:GN_AGS\n:GN_ISRES\n:GN_ESCH\n:LN_COBYLA\n:LN_BOBYQA\n:LN_NEWUOA\n:LN_NEWUOA_BOUND\n:LN_PRAXIS\n:LN_NELDERMEAD\n:LN_SBPLX\n:LD_MMA\n:LD_CCSAQ\n:LD_SLSQP\n:LD_TNEWTON_PRECOND_RESTART\n:LD_TNEWTON_PRECOND\n:LD_TNEWTON_RESTART\n:LD_TNEWTON\n:LD_VAR2\n:LD_VAR1\n:AUGLAG\n:AUGLAG_EQ","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"For a description of the above algorithms, please refer to the algorithms section of NLopt's documentation.","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"Disclaimer:","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"Not all the algorithms have been tested with Nonconvex. So if you try one and it doesn't work, please open an issue.","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"","category":"page"},{"location":"algorithms/nlopt/#Options","page":"Various optimization algorithms from NLopt.jl","title":"Options","text":"","category":"section"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"The options keyword argument to the optimize function shown above must be an instance of the NLoptOptions struct when the algorihm is an NLoptAlg. To specify options use keyword arguments in the constructor of NLoptOptions, e.g:","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"options = NLoptOptions(ftol_rel = 1e-4)","category":"page"},{"location":"algorithms/nlopt/","page":"Various optimization algorithms from NLopt.jl","title":"Various optimization algorithms from NLopt.jl","text":"All the other options that can be set for each algorithm can be found in the algorithms section section of NLopt's documentation.","category":"page"},{"location":"algorithms/surrogate/#Surrogate-assisted-continuous-and-discrete,-constrained-optimization","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"","category":"section"},{"location":"algorithms/surrogate/#Description","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Description","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"Surrogate-assisted optimization replaces expensive functions in the objecitve and/or constraints by a surrogate. In Nonconvex, a Gaussian process (GP) from AbstractGPs.jl is used. A certain amount of \"benefit of the doubt\" is given to solutions by minimizing:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"μ(x) - η * σ(x)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"where μ(x) and σ(x) are the mean and standard deviation of the posterior GP's prediction of the function's value at point x. η is a positive number that resembles how much benefit of the doubt we want to give the solution. A high η means more exploration and a low η means more exploitation.","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"Similarly, expensive inequality constraints are replaced by:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"μ(x) - η * σ(x) <= 0","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"giving the solution the benefit of the doubt. And each equality constraint is replaced by 2 inequality constraints as such:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"μ(x) - η * σ(x) <= 0 <= μ(x) + η * σ(x)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"Once the surrogates are formed, they are solved using a sub-optimizer to get the next query point to update the surrogate model. Prior to the optimization loop, initialization is done using a number of points using a Sobol sequence of points.","category":"page"},{"location":"algorithms/surrogate/#Quick-start","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Quick start","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"using Nonconvex\nNonconvex.@load BayesOpt\n\nf(x) = sqrt(x[2])\ng(x, a, b) = (a*x[1] + b)^3 - x[2]\n\nmodel = Model()\nset_objective!(model, f, flags = [:expensive])\naddvar!(model, [1e-4, 1e-4], [10.0, 10.0])\nadd_ineq_constraint!(model, x -> g(x, 2, 0), flags = [:expensive])\nadd_ineq_constraint!(model, x -> g(x, -1, 1))\n\nalg = BayesOptAlg(IpoptAlg())\noptions = BayesOptOptions(\n    sub_options = IpoptOptions(),\n    maxiter = 50, ftol = 1e-4, ctol = 1e-5,\n)\nr = optimize(model, alg, [1.234, 2.345], options = options)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"Note that the flags keyword argument was used when defining the objective and constraints and set to [:expensive]. This is a hint to Nonconvex to use a surrogate in place of these constraint functions.","category":"page"},{"location":"algorithms/surrogate/#Construct-an-instance","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"To construct an instance of the surrogate-assisted optimization algorithm, use:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"alg = BayesOptAlg(subsolver)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"where subsolver is any Nonconvex optimizer to be used to solve the surrogate model.","category":"page"},{"location":"algorithms/surrogate/#Options","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Options","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"The options keyword argument to the optimize function shown above must be an instance of the BayesOptOptions struct when the algorihm is a BayesOptAlg. The following options can be set using keyword arguments when constructing BayesOptOptions.","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"sub_options: options for the sub-optimizer\nmaxiter: the maximum number of iterations in the Bayesian optimization routine\ninitialize: true by default. If true, the GP will be initialized using a Sobol sequence of query points\nninit: number of initialization points\nctol: feasibility tolerance when accepting a solution\nftol: relative tolerance in the function value\npostoptimize: true by default. If true, a local optimization procedure will be used after the Bayesian optimization is completed.\nkernel: the GP kernel used. All the kernels from KernelFunctions.jl are available.\nnoise: GP observation noise parameter\nstd_multiple: η in the description of the algorithm above.","category":"page"},{"location":"algorithms/surrogate/#Advanced:-manually-constructing-surrogate-functions","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Advanced: manually constructing surrogate functions","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"Sometimes a function used in the model may need to be replaced by a surrogate but not the entire objective or constraint function. In this case, the surrogate function can be defined explicitly and passed in to the optimize function using the keyword argument surrogates. A surrogate for the function f can be constructed using:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"s1 = Nonconvex.surrogate(f, x0)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"where x0 is the initial query point. The output of s1(x) will be an interval from [IntervalArithmetic.jl])(https://github.com/JuliaIntervals/IntervalArithmetic.jl) with lo and hi fields, where lo = μ(x) - η * σ(x) and hi = μ(x) + η σ(x). This interval will propagate through the objective function and/or contraint functions outputting an interval or an array of intervals at the end.","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"To define the objective or constraint functions using the manually contructed surrogates, one needs to return the lo field of the output manually at the end of the objective function or inequality constraint function definitions. Equality constraints should also be transformed to a 2-block inequality constraint manually as described above. When manually passing surrogates to the optimize function, the :expensive flag is redundant and will be ignored.","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"Example:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assisted continuous and discrete, constrained optimization","title":"Surrogate-assisted continuous and discrete, constrained optimization","text":"x0 = [1.234, 2.345]\ns1 = Nonconvex.surrogate(f, x0)\ns2 = Nonconvex.surrogate(x -> [g(x, 2, 0), g(x, -1, 1)], x0)\n\nmodel = Model()\nset_objective!(model, x -> s1(x).lo)\naddvar!(model, [1e-4, 1e-4], [10.0, 10.0])\nadd_ineq_constraint!(model, x -> getproperty.(s2(x), :lo))\nalg = BayesOptAlg(IpoptAlg())\noptions = BayesOptOptions(\n    sub_options = IpoptOptions(print_level = 0), maxiter = 50, ctol = 1e-4,\n    ninit = 2, initialize = true, postoptimize = false,\n)\nr = optimize(model, alg, x0, options = options, surrogates = [s1, s2])","category":"page"},{"location":"gradients/other_ad/#Using-other-AD-packages","page":"Using other AD packages","title":"Using other AD packages","text":"","category":"section"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"Nonconvex uses Zygote and ForwardDiff by default. There are other AD packages in Julia with different tradeoffs. It is possible to use other AD packages to differentiate specific functions in Nonconvex using function modifiers.","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"AbstractDifferentiation.jl is a package that defines a unified API for multiple AD packages. Each AD package has a \"backend type\" in AbstractDifferentiation. You can use any AbstractDifferentiation-compatible AD package to differentiate specific functions in Nonconvex. The list of AbstractDifferentiation-compatible AD packages (other than Zygote) are:","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"FiniteDifferences.jl\nForwardDiff.jl\nReverseDiff.jl\nTracker.jl","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"For more on how to construct a backend struct for each AD package, please refer to the README file of the AbstractDifferentiation repository.","category":"page"},{"location":"gradients/other_ad/#abstractdiffying-a-function","page":"Using other AD packages","title":"abstractdiffying a function","text":"","category":"section"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"In order to use a specific AbstractDifferentiation-compatible AD package to differentiate a function f(x...) used in a Nonconvex objective/constraint, you can use the abstractdiffy function modifier from Nonconvex:","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"F = abstractdiffy(f, backend, x...)\nF(x...)","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"where backend is an AbstractDifferentiation backend struct for the desired AD package, and x are all the input arguments to f.","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"The following are common backend choices:","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"AbstractDifferentiation.ForwardDiffBackend() for ForwardDiff\nAbstractDifferentiation.FiniteDifferencesBackend() for FiniteDifferences\nAbstractDifferentiation.ReverseDiffBackend() for ReverseDiff\nAbstractDifferentiation.TrackerBackend() for Tracker","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"Note that in order to define such backend type, one must first load the AbstractDifferentiation package as well as the AD package to be used, e.g.:","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"using AbstractDifferentiation, ReverseDiff\n\nbackend = AbstractDifferentiation.ReverseDiffBackend()","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"Having defined F like this, whenever ForwardDiff or any ChainRules-compatible AD package such as Zygote is used to differentiate F, the AD package corresponding to the chosen backend will be used instead.","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"To use ForwardDiff as the backend of choice, a shortcut is also available using the forwarddiffy function modifier instead of the more general abstractdiffy:","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"F = forwarddiffy(f, x...)\nF(x...)","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"which is short for:","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"backend = AbstractDifferentiation.ForwardDiffBackend()\nF = abstractdiffy(f, backend, x...)","category":"page"},{"location":"gradients/other_ad/#abstractdiffying-a-model","page":"Using other AD packages","title":"abstractdiffying a model","text":"","category":"section"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"Instead of abstractdiffying or forwarddiffying one function at a time, the user can instead abstractdiffy or forwarddiffy an entire Nonconvex model including the objective, all the inequality constraint functions, all the equality constraint functions and all the semidefinite constraint functions.","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"ad_model = abstractdiffy(model, backend)","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"where model is of type Model or DictModel. ad_model can now be optimized using any of the Nonconvex algorithms compatible with the model. Similarly, forwarddiffy can be  used on an entire model:","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"fd_model = forwarddiffy(model)","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"By default, the objective and all the constraint functions will be modified with abstractdiffy/forwarddiffy. To prevent the modification of some component of the model, any of the following keyword arguments can be set to false (default is true):","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"objective = false\nineq_constraints = false\neq_constraints = false\nsd_constraints = false","category":"page"},{"location":"gradients/other_ad/","page":"Using other AD packages","title":"Using other AD packages","text":"Setting the objective, ineq_constraints, eq_constraints, and/or sd_constraints keyword arguments to false (default is true) will prevent the modification of the objective, all the inequality constraint functions, all the equality constraint functions, and/or all the semidefinite constraint functions respectively.","category":"page"},{"location":"gradients/chainrules_fd/#Using-ChainRules-in-ForwardDiff","page":"Using ChainRules in ForwardDiff","title":"Using ChainRules in ForwardDiff","text":"","category":"section"},{"location":"gradients/chainrules_fd/","page":"Using ChainRules in ForwardDiff","title":"Using ChainRules in ForwardDiff","text":"ForwardDiff is a forward-mode AD package that pre-dates ChainRules. ForwardDiff therefore does not use the frules defined in ChainRules. In order to force ForwardDiff to use the frule defined for a function, one can use the Nonconvex.NonconvexUtils.@ForwardDiff_frule macro provided in Nonconvex. This is useful in case ForwardDiff is used for the entire function but a component of this function has an efficient frule defined that you want to take advantage of. To force ForwardDiff to use the frule defined for a function f(x::AbstractVector), you can use:","category":"page"},{"location":"gradients/chainrules_fd/","page":"Using ChainRules in ForwardDiff","title":"Using ChainRules in ForwardDiff","text":"Nonconvex.NonconvexUtils.@ForwardDiff_frule f(x::AbstractVector{<:ForwardDiff.Dual})","category":"page"},{"location":"gradients/chainrules_fd/","page":"Using ChainRules in ForwardDiff","title":"Using ChainRules in ForwardDiff","text":"The signature of the function specifies the method that will be re-directed to use the frule from ChainRules. Such frule therefore needs to be defined for f to begin with. f with multiple inputs, scalar inputs and other input collection types are also supported.","category":"page"},{"location":"gradients/gradients/#Gradients,-Jacobians-and-Hessians","page":"Overview","title":"Gradients, Jacobians and Hessians","text":"","category":"section"},{"location":"gradients/gradients/","page":"Overview","title":"Overview","text":"By default, Nonconvex uses:","category":"page"},{"location":"gradients/gradients/","page":"Overview","title":"Overview","text":"The reverse-mode automatic differentiation (AD) package, Zygote.jl, for computing gradients and Jacobians of functions, and\nThe forward-mode AD package, ForwardDiff.jl, over  Zygote.jl for computing Hessians.","category":"page"},{"location":"gradients/gradients/","page":"Overview","title":"Overview","text":"However, one can force Nonconvex to use other AD packages or even user-defined gradients and Hessians using special function modifiers. Those special function modifiers customize the behaviour of functions without enforcing the same behaviour on other functions. For instance:","category":"page"},{"location":"gradients/gradients/","page":"Overview","title":"Overview","text":"A specific AD package can be used for one constraint function while the default AD packages are used for other functions in the optimization problem.\nThe history of gradients of a specific function can be stored without storing all the gradients of all the functions.\nFor functions with a sparse Jacobian or Hessian, the sparsity can be used to speedup the AD using sparse, forward-mode AD for these functions.","category":"page"},{"location":"gradients/gradients/","page":"Overview","title":"Overview","text":"In some cases, function modifiers can even be composed on top of each other to create more complex behaviours. ","category":"page"},{"location":"gradients/gradients/","page":"Overview","title":"Overview","text":"In Nonconvex, function modifiers modify the behaviour of a function when differentiated once or twice using either ForwardDiff or any ChainRules-compatible AD package, such as Zygote.jl. The following features are all implemented in NonconvexUtils.jl and re-exported from Nonconvex.","category":"page"},{"location":"gradients/gradients/#Table-of-contents","page":"Overview","title":"Table of contents","text":"","category":"section"},{"location":"gradients/gradients/","page":"Overview","title":"Overview","text":"Pages = [\"user_defined.md\", \"other_ad.md\", \"chainrules_fd.md\", \"sparse.md\", \"symbolic.md\", \"implicit.md\", \"history.md\"]\nDepth = 3","category":"page"},{"location":"gradients/history/#Storing-history-of-gradients","page":"Storing history of gradients","title":"Storing history of gradients","text":"","category":"section"},{"location":"gradients/history/","page":"Storing history of gradients","title":"Storing history of gradients","text":"Often one may want to store intermediate solutions, function values and gradients for visualisation or post-processing. This is currently not possible with Nonconvex.jl as not all solvers support a callback mechanism. To workround this, the TraceFunction modifier can be used to store input, output and optionally gradient values during the optimization:","category":"page"},{"location":"gradients/history/","page":"Storing history of gradients","title":"Storing history of gradients","text":"F = TraceFunction(f; on_call = false, on_grad = true)","category":"page"},{"location":"gradients/history/","page":"Storing history of gradients","title":"Storing history of gradients","text":"F can now  be used inplace of f in objective and/or constraint functions in a Nonconvex model. If the on_call keyword argument is set to true (default is true), the input and output values are stored every time the function F is called. If the on_grad keyword argument is set to true (default is true), the input, output and gradient values are stored every time the function F is differentiated with either ForwardDiff or any ChainRules-compatible AD package such as Zygote.jl. The history is stored in F.trace. The TraceFunction modifier can be compsed with other AD-centric function modifiers in Nonconvex, e.g. the sparsify or symbolify function modifiers.","category":"page"},{"location":"algorithms/mma/#Method-of-moving-asymptotes-in-pure-Julia","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"","category":"section"},{"location":"algorithms/mma/#Description","page":"Method of moving asymptotes in pure Julia","title":"Description","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"There are 2 versions of the method of moving asymptotes (MMA) that are available in NonconvexMMA.jl:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"The original MMA algorithm from the 1987 paper.\nThe globally convergent MMA (GCMMA) algorithm from the 2002 paper.","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"The MMA algorithm only supports inequality constraints. However, the original algorithm was slightly generalized to handle infinite variable bounds.","category":"page"},{"location":"algorithms/mma/#Quick-start","page":"Method of moving asymptotes in pure Julia","title":"Quick start","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using MMA.","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"using Nonconvex\nNonconvex.@load MMA\n\nalg = MMA87() # or MMA02()\noptions = MMAOptions()\nresult = optimize(model, alg, x0, options = options, convcriteria = KKTCriteria())","category":"page"},{"location":"algorithms/mma/#Construct-an-instance","page":"Method of moving asymptotes in pure Julia","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"To construct an instance of the original MMA algorithm, use:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"alg = MMA87()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"or alternatively:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"alg = MMA()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"To construct an instance of the globally convergent MMA algorithm, use:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"alg = MMA02()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"or alternatively:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"alg = GCMMA()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"MMA87\nMMA02","category":"page"},{"location":"algorithms/mma/#NonconvexMMA.MMA87","page":"Method of moving asymptotes in pure Julia","title":"NonconvexMMA.MMA87","text":"MMA87\n\nThe original method of moving asymptotes (MMA) algorithm from the 1987 paper.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#NonconvexMMA.MMA02","page":"Method of moving asymptotes in pure Julia","title":"NonconvexMMA.MMA02","text":"MMA02\n\nThe globally convergent method of moving asymptotes (MMA) algorithm from the 2002 paper.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Options","page":"Method of moving asymptotes in pure Julia","title":"Options","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"To specify options for the MMA algorithm, you can construct an instance of MMAOptions and use keyword arguments.","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"MMAOptions","category":"page"},{"location":"algorithms/mma/#NonconvexMMA.MMAOptions","page":"Method of moving asymptotes in pure Julia","title":"NonconvexMMA.MMAOptions","text":"MMAOptions\n\nA struct that stores all the options of the MMA algorithms. Th following are the fields of MMAOptions:\n\nmaxiter: the maximum number of inner iterations. For MMA87, there is 1 inner iteration per outer iteration.\nouter_maxiter: the maximum number of outer iterations.\nmaxinner: the maximum number of inner iterations per outer iteration of MMA02. Not applicable for MMA87.\ntol: a tolerance struct of type Tolerance.\ns_init: defined in the original MMA02 paper.\ns_incr: defined in the original MMA02 paper.\ns_decr: defined in the original MMA02 paper.\nstore_trace: if true, a trace will be stored.\ndual_options: the options passed to the dual optimizer from Optim.jl.\nconvcriteria: an instance of ConvergenceCriteria that specifies the convergence criteria of the MMA algorithm.\nverbose: true/false, when true prints convergence statistics.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"The tol option in MMA can be set to an instance of the Tolerance struct:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"Tolerance\nNonconvexCore.ConvergenceState","category":"page"},{"location":"algorithms/mma/#NonconvexCore.Tolerance","page":"Method of moving asymptotes in pure Julia","title":"NonconvexCore.Tolerance","text":"Tolerance\n\nA struct specifying the different tolerances used to assess the convergence of the algorithms. The following are the fields of Tolerance:\n\nx: the tolerance for Δx in ConvergenceState. x_converged will be true if Δx is less than the x tolerance in Tolerance. This is used to assess convergence when the GenericCriteria is used as the convergence criteria. \nfabs: the tolerance for Δf in ConvergenceState. f_converged will be true if Δf is less than the fabs tolerance in Tolerance. This is used to assess convergence when the GenericCriteria is used as the convergence criteria.\nfrel: the tolerance for relΔf in ConvergenceState. f_converged will be true if relΔf is less than the frel tolerance in Tolerance. This is used to assess convergence when the GenericCriteria is used as the convergence criteria.\nkkt: the KKT tolerance. kkt_converged in ConvergenceState will be true if the kkt_residual is less than the KKT tolerance. And ipopt_converged in ConvergenceState will be true if ipopt_residual is less than the KKT tolerance. This is used to assess convergence when the KKTCriteria, the ScaledKKTCriteria or IpoptCriteria criteria is used as the convergence criteria.\ninfeas: the maximum infeasibility tolerance. infeas_converged in ConvergenceState will be true if the maximum infeasibility is less than the infeasibility tolerance. This is used to assess convergence regardless of the convergence criteria used.\n\nFor more on convergence criteria, see GenericCriteria, KKTCriteria, ScaledKKTCriteria and IpoptCriteria.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#NonconvexCore.ConvergenceState","page":"Method of moving asymptotes in pure Julia","title":"NonconvexCore.ConvergenceState","text":"ConvergenceState\n\nA struct that summarizes the convergence state of a solution. The fields in this struct are:\n\nΔx: the infinity norm of the change in the solution x.\nΔf: the change in the objective value f.\nrelΔf: the ratio of change in the objective value f.\nkkt_residual: the Karush-Kuhn-Tucker (KKT) residual of the solution. If ScaledKKTCriteria is used instead of KKTCriteria, the kkt_residual will be divided by a factor.\nipopt_residual: the modified KKT residual used in the IPOPT solver.\ninfeas: maximum infeasibility amount. This is 0 if the solution is feasible.\nx_converged: true if Δx is less than the x tolerance in MMAOptions.\nfabs_converged: true if Δf is less than the f tolerance in MMAOptions.\nfrel_converged: true if relΔf is less than the f tolerance in MMAOptions.\nkkt_converged: true if the kkt_residual is less than the KKT tolerance in MMAOptions.\nipopt_converged: true if the ipopt_residual is less than the KKT tolerance in MMAOptions.\ninfeas_converged: true if infeas is less than the infeasibility tolerance in MMAOptions.\nf_increased: true if the objective value of the current solution is higher than that of the previous solution.\nconverged: true if the solution satisfies the convergence criteria of choice. See ConvergenceCriteria for more on the different convergence criteria available.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Convergence-criteria","page":"Method of moving asymptotes in pure Julia","title":"Convergence criteria","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"There are 4 convergence criteria available for the MMA algorithm:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"GenericCriteria\nKKTCriteria\nScaledKKTCriteria\nIpoptCriteria","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"NonconvexCore.ConvergenceCriteria\nNonconvexCore.GenericCriteria\nNonconvexCore.KKTCriteria\nNonconvexCore.ScaledKKTCriteria\nNonconvexCore.IpoptCriteria\nNonconvexCore.assess_convergence!","category":"page"},{"location":"algorithms/mma/#NonconvexCore.ConvergenceCriteria","page":"Method of moving asymptotes in pure Julia","title":"NonconvexCore.ConvergenceCriteria","text":"ConvergenceCriteria\n\nThis an abstract type with 4 subtypes:\n\nGenericCriteria\nKKTCriteria\nScaledKKTCriteria\nIpoptCriteria\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#NonconvexCore.GenericCriteria","page":"Method of moving asymptotes in pure Julia","title":"NonconvexCore.GenericCriteria","text":"GenericCriteria\n\nThis is a generic convergence criteria that uses:\n\nThe maximum change in the solution, Δx,\nThe change in the objective value, Δf, and\nThe change percentage in the objective value, Δf, and\nThe maximum infeasibility infeas.\n\nto assess convergence. More details are given in assess_convergence!.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#NonconvexCore.KKTCriteria","page":"Method of moving asymptotes in pure Julia","title":"NonconvexCore.KKTCriteria","text":"KKTCriteria\n\nThis convergence criteria uses the Karush-Kuhn-Tucker residual and maximum infeasibility to assess convergence. More details are given in assess_convergence!.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#NonconvexCore.ScaledKKTCriteria","page":"Method of moving asymptotes in pure Julia","title":"NonconvexCore.ScaledKKTCriteria","text":"ScaledKKTCriteria\n\nThis convergence criteria uses another scaled version of the Karush-Kuhn-Tucker (KKT) residual and maximum infeasibility to assess convergence. In particular if the objective was scaled by a factor m, the KKT residual will be scaled down by a factor max(m, 1/m). This scaling was found to make the convergence criteria less sensitive to scale compared to using the traditional KKT residual. More details are given in assess_convergence!. \n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#NonconvexCore.IpoptCriteria","page":"Method of moving asymptotes in pure Julia","title":"NonconvexCore.IpoptCriteria","text":"IpoptCriteria\n\nThis convergence criteria uses a scaled version of the Karush-Kuhn-Tucker (KKT) residual and maximum infeasibility to assess convergence. This scaled KKT residual is used in the IPOPT nonlinear programming solver as explained in this paper. More details are given in assess_convergence!. \n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#NonconvexCore.assess_convergence!","page":"Method of moving asymptotes in pure Julia","title":"NonconvexCore.assess_convergence!","text":"assess_convergence!(\n    solution::Solution,\n    model::AbstractModel,\n    tol::Tolerance,\n    criteria::ConvergenceCriteria,\n    verbose::Bool,\n    iter::Int\n)\n\nEvaluates the convergence state solution.convstate given the current solution, solution, the tolerance, tol, and the convergence criteria criteria. solution.convstate.converged is then updated.\n\nIf criteria is an instance of GenericCriteria, converged = (x_converged || f_converged) && infeas_converged. x_converged, f_converged and infeas_converged are explained in Tolerance. If criteria is an instance of KKTCriteria or ScaledKKTCriteria, converged = kkt_converged && infeas_converged. kkt_converged and infeas_converged are explained in Tolerance. If criteria is an instance of IpoptCriteria, converged = ipopt_converged && infeas_converged. ipopt_converged and infeas_converged are explained in Tolerance.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"To specify the convergence criteria, use:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"converiteria = GenericCriteria()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes in pure Julia","title":"Method of moving asymptotes in pure Julia","text":"replacing GenericCriteria() by KKTCriteria(), ScaledKKTCriteria() or IpoptCriteria().","category":"page"},{"location":"#Nonconvex.jl-Documentation","page":"Getting started","title":"Nonconvex.jl Documentation","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Nonconvex.jl is a Julia package that implements and wraps a number of constrained nonlinear and mixed integer nonlinear programming solvers. There are 3 focus points of Nonconvex.jl compared to similar packages such as JuMP.jl and NLPModels.jl:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Emphasis on a function-based API. Objectives and constraints are normal Julia functions.\nThe ability to nest algorithms to create more complicated algorithms.\nThe ability to automatically handle structs and different container types in the decision variables by automatically vectorizing and un-vectorizing them in an AD compatible way.","category":"page"},{"location":"#Installing-Nonconvex","page":"Getting started","title":"Installing Nonconvex","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"To install Nonconvex.jl, open a Julia REPL and type ] to enter the package mode. Then run:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"add Nonconvex","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Alternatively, copy and paste the following code to a Julia REPL:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using Pkg; Pkg.add(\"Nonconvex\")","category":"page"},{"location":"#Loading-Nonconvex","page":"Getting started","title":"Loading Nonconvex","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"To load and start using Nonconvex.jl, run:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using Nonconvex","category":"page"},{"location":"#Quick-start","page":"Getting started","title":"Quick start","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"using Nonconvex\nNonconvex.@load NLopt\n\nf(x) = sqrt(x[2])\ng(x, a, b) = (a*x[1] + b)^3 - x[2]\n\nmodel = Model(f)\naddvar!(model, [0.0, 0.0], [10.0, 10.0])\nadd_ineq_constraint!(model, x -> g(x, 2, 0))\nadd_ineq_constraint!(model, x -> g(x, -1, 1))\n\nalg = NLoptAlg(:LD_MMA)\noptions = NLoptOptions()\nr = optimize(model, alg, [1.0, 1.0], options = options)\nr.minimum # objective value\nr.minimizer # decision variables","category":"page"},{"location":"#Table-of-contents","page":"Getting started","title":"Table of contents","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Pages = [\"problem/problem.md\", \"algorithms/algorithms.md\", \"gradients/gradients.md\", \"result.md\"]\nDepth = 3","category":"page"},{"location":"algorithms/algorithms/#Algorithms","page":"Overview","title":"Algorithms","text":"","category":"section"},{"location":"algorithms/algorithms/#Overview-of-algorithms","page":"Overview","title":"Overview of algorithms","text":"","category":"section"},{"location":"algorithms/algorithms/","page":"Overview","title":"Overview","text":"A summary of all the algorithms available in Nonconvex through different packages is shown in the table below. Scroll right to see more columns and see a description of the columns below the table.","category":"page"},{"location":"algorithms/algorithms/","page":"Overview","title":"Overview","text":"Algorithm name Is meta-algorithm? Algorithm package Order Finite bounds Infinite bounds Inequality constraints Equality constraints Semidefinite constraints Integer variables\nMethod of moving asymptotes (MMA) ❌ NonconvexMMA.jl (pure Julia) or NLopt.jl 1 ✅ ✅ ✅ ❌ ❌ ❌\nPrimal dual interior point method ❌ Ipopt.jl 1 or 2 ✅ ✅ ✅ ✅ ❌ ❌\nDIviding RECTangles algorithm (DIRECT) ❌ NLopt.jl 0 ✅ ❌ ✅ ❌ ❌ ❌\nControlled random search (CRS) ❌ NLopt.jl 0 ✅ ✅ ❌ ❌ ❌ ❌\nMulti-Level Single-Linkage (MLSL) Limited NLopt.jl Depends on sub-solver ✅ ✅ ❌ ❌ ❌ ❌\nStoGo ❌ NLopt.jl 1 ✅ ❌ ❌ ❌ ❌ ❌\nAGS ❌ NLopt.jl 0 ✅ ❌ ✅ ❌ ❌ ❌\nImproved Stochastic Ranking Evolution Strategy (ISRES) ❌ NLopt.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nESCH ❌ NLopt.jl 0 ✅ ✅ ❌ ❌ ❌ ❌\nCOBYLA ❌ NLopt.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nBOBYQA ❌ NLopt.jl 0 ✅ ✅ ❌ ❌ ❌ ❌\nNEWUOA ❌ NLopt.jl 0 ✅ ✅ ❌ ❌ ❌ ❌\nPrincipal AXIS (PRAXIS) ❌ NLopt.jl 0 ✅ ✅ ❌ ❌ ❌ ❌\nNelder Mead ❌ NLopt.jl 0 ✅ ✅ ❌ ❌ ❌ ❌\nSubplex ❌ NLopt.jl 0 ✅ ✅ ❌ ❌ ❌ ❌\nCCSAQ ❌ NLopt.jl 1 ✅ ✅ ✅ ❌ ❌ ❌\nSLSQP ❌ NLopt.jl 1 ✅ ✅ ✅ ✅ ❌ ❌\nTNewton ❌ NLopt.jl 1 ❌ ✅ ❌ ❌ ❌ ❌\nShifted limited-memory variable-metric ❌ NLopt.jl 1 ❌ ✅ ❌ ❌ ❌ ❌\nAugmented Lagrangian in NLopt Limited NLopt.jl Depends on sub-solver ✅ ✅ ✅ ✅ ❌ ❌\nAugmented Lagrangian in Percival ❌ Percival.jl 1 or 2 ✅ ✅ ✅ ✅ ❌ ❌\nMultiple trajectory search ❌ NonconvexSearch.jl 0 ✅ ❌ ❌ ❌ ❌ ❌\nBranch and bound for mixed integer nonlinear programming ❌ Juniper.jl 1 or 2 ✅ ✅ ✅ ✅ ❌ ✅\nSequential polyhedral outer-approximations for mixed integer nonlinear programming ❌ Pavito.jl 1 or 2 ✅ ✅ ✅ ✅ ❌ ✅\nEvolutionary centers algorithm (ECA) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nDifferential evolution (DE) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nParticle swarm optimization (PSO) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nArtificial bee colony (ABC) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nGravitational search algorithm (GSA) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nSimulated annealing (SA) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nWhale optimization algorithm (WOA) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nMachine-coded compact genetic algorithm (MCCGA) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nGenetic algorithm (GA) ❌ Metaheuristics.jl 0 ✅ ✅ ✅ ✅ ❌ ❌\nNonlinear optimization with the MADS algorithm (NOMAD) ❌ NOMAD.jl 0 ✅ ✅ ✅ Limited ❌ ✅\nTopology optimization of binary structures (TOBS) ❌ NonconvexTOBS.jl 1 Binary ❌ ✅ ❌ ❌ Binary\nHyperband ✅ Hyperopt.jl Depends on sub-solver ✅ ❌ Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver\nRandom search ✅ Hyperopt.jl Depends on sub-solver ✅ ❌ Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver\nLatin hypercube search ✅ Hyperopt.jl Depends on sub-solver ✅ ❌ Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver\nSurrogate assisted optimization ✅ NonconvexBayesian.jl Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver\nLog barrier method for nonlinear semidefinite constraint handling ✅ NonconvexSemidefinite.jl Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver Depends on sub-solver ✅ Depends on sub-solver","category":"page"},{"location":"algorithms/algorithms/","page":"Overview","title":"Overview","text":"The following is an explanation of all the columns in the table:","category":"page"},{"location":"algorithms/algorithms/","page":"Overview","title":"Overview","text":"Algorithm name. This is the name of the algorithm and/or its acronym. Some algorithms have multiple variants implemented in their respective packages. When that's the case, the whole family of algorithms is mentioned only once.\nIs meta-algorithm? Some algorithms are meta-algorithms that call a sub-algorithm to do the optimization after transforming the problem. In this case, a lot of the properties of the meta-algorithm are inherited from the sub-algorithm. So if the sub-algorithm requires gradients or Hessians of functions in the model, the meta-algorithm will also require gradients and Hessians of functions in the model. Fields where the property of the meta-algorithm is inherited from the sub-solver are indicated using the \"Depends on sub-solver\" entry. Some algorithms in NLopt have a \"Limited\" meta-algorithm status because they can only be used to wrap algorithms from NLopt.\nAlgorithm package. This is the Julia package that either implements the algorithm or calls it from another programming language. Nonconvex wraps all these packages using a consistent API while allowing each algorithm to be customized where possible and have its own set of options.\nOrder. This is the order of the algorithm. Zero-order algorithms only require the evaluation of the objective and constraint functions, they don't require any gradients or Hessians of objective and constraint functions. First-order algorithms require both the value and gradients of objective and/or constraint functions. Second-order algorithms require the value, gradients and Hessians of objective and/or constraint functions.\nFinite bounds. This is true if the algorithm supports finite lower and upper bound constraints on the decision variables. One special case is the TOBS algorithm which only supports binary decision variables so an entry of \"Binary\" is used instead of true/false.\nInfinite bounds. This is true if the algorithm supports unbounded decision variables either from below, above or both.\nInequality constraints. This is true if the algorithm supports nonlinear inequality constraints.\nEquality constraints. This is true if the algorithm supports nonlinear equality constraints. Algorithms that only support linear equality constraints are given an entry of \"Limited\".\nSemidefinite constraints. This is true if the algorithm supports nonlinear semidefinite constraints.\nInteger variables. This is true if the algorithm supports integer/discrete/binary decision variables, not just continuous. One special case is the TOBS algorithm which only supports binary decision variables so an entry of \"Binary\" is used instead of true/false.","category":"page"},{"location":"algorithms/algorithms/#Wrapper-packages","page":"Overview","title":"Wrapper packages","text":"","category":"section"},{"location":"algorithms/algorithms/","page":"Overview","title":"Overview","text":"The JuliaNonconvex organization hosts a number of packages which wrap other optimization packages in Julia or implement their algorithms. The correct wrapper package is loaded using the Nonconvex.@load macro with the algorithm or package name. The following is a summary of all the wrapper packages in the JuliaNonconvex organization. To view the documentation of each package, click on the blue docs badge in the last column.","category":"page"},{"location":"algorithms/algorithms/","page":"Overview","title":"Overview","text":"Package Description Tests Coverage Docs\nNonconvexMMA.jl Method of moving asymptotes implementation in pure Julia (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexIpopt.jl Ipopt.jl wrapper (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexNLopt.jl NLopt.jl wrapper (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexPercival.jl Percival.jl wrapper (an augmented Lagrangian algorithm implementation) (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexJuniper.jl Juniper.jl wrapper (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexPavito.jl Pavito.jl wrapper (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexSemidefinite.jl Nonlinear semi-definite programming algorithm (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexMultistart.jl Multi-start optimization algorithms (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexBayesian.jl Constrained Bayesian optimization implementation (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexSearch.jl Multi-trajectory and local search methods (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexTOBS.jl Binary optimization algorithm called \"topology optimization of binary structures\" (TOBS) which was originally developed in the context of optimal distribution of material in mechanical components. (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexMetaheuristics.jl Metaheuristic gradient-free optimization algorithms as implemented in Metaheuristics.jl. (Image: Build Status) (Image: Coverage) (Image: )\nNonconvexNOMAD.jl NOMAD algorithm as wrapped in the NOMAD.jl. (Image: Build Status) (Image: Coverage) (Image: )","category":"page"},{"location":"problem/queries/#Model-queries","page":"Querying models","title":"Model queries","text":"","category":"section"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"There are a number of information you can query about the model after constructing it. These can be useful to check that the model was defined correctly or in the post-processing step after the model has been optimized.","category":"page"},{"location":"problem/queries/#Number-of-decision-variables","page":"Querying models","title":"Number of decision variables","text":"","category":"section"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To query the number of decision variables in a model, use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"NonconvexCore.getnvars(model)","category":"page"},{"location":"problem/queries/#Number-of-constraints","page":"Querying models","title":"Number of constraints","text":"","category":"section"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To query the number of inequality constraints in a model, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"NonconvexCore.getnineqconstraints(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"A vector-valued constraint will be counted only once.","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To query the number of equality constraints, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"NonconvexCore.getneqconstraints(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To query the number of semidefinite constraints, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"NonconvexCore.getnsdconstraints(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To query the total number of constraints in a model, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"NonconvexCore.getnconstraints(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"This is the sum of all the previous queries.","category":"page"},{"location":"problem/queries/#Problem-dimension","page":"Querying models","title":"Problem dimension","text":"","category":"section"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To get a quick overview of the number of constraints and variables in the model, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"NonconvexCore.getdim(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"which is  short for:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"(NonconvexCore.getnconstraints(model), NonconvexCore.getnvars(model))","category":"page"},{"location":"problem/queries/#Objective-and-constraint-functions","page":"Querying models","title":"Objective and constraint functions","text":"","category":"section"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"You can get the objective and constraint functions as regular Julia functions which can be evaluated. To get the objective function, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"obj = NonconvexCore.getobjective(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To get a function for all the inequality constraints, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"ineq = NonconvexCore.getineqconstraints(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To get a function for all the equality constraints, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"ineq = NonconvexCore.geteqconstraints(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To get a function for all the semideifnite constraint functions, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"ineq = NonconvexCore.getsdconstraints(model)","category":"page"},{"location":"problem/queries/#Initial-solution","page":"Querying models","title":"Initial solution","text":"","category":"section"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"You can the initial solution using:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"x0 = NonconvexCore.getinit(model)","category":"page"},{"location":"problem/queries/#Variables-bounds","page":"Querying models","title":"Variables bounds","text":"","category":"section"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"You can query the maximum variable bounds for all the variables using:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"NonconvexCore.getmax(model)","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"Similarly, you can query the minimum variable bounds for all the variables using:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"NonconvexCore.getmin(model)","category":"page"},{"location":"problem/queries/#Integrality-constraints","page":"Querying models","title":"Integrality constraints","text":"","category":"section"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"To get the vector indiciting which variables are integer, you can use:","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"model.integer","category":"page"},{"location":"problem/queries/","page":"Querying models","title":"Querying models","text":"which will be a BitVector (similar to a vector of Bool) with true corresponding to an integer constraint and false corresponding to a continuous variable.","category":"page"}]
}
